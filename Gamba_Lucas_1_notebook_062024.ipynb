{"cells": [{"metadata": {"id": "441159cc"}, "id": "441159cc", "cell_type": "markdown", "source": "# D\u00e9ployez un mod\u00e8le dans le cloud\n\n\n# Sommaire :\n\n**1. Pr\u00e9ambule**<br />\n&emsp;1.1 Probl\u00e9matique<br />\n&emsp;1.2 Objectifs dans ce projet<br />\n&emsp;1.3 D\u00e9roulement des \u00e9tapes du projet<br />\n**2. Choix techniques g\u00e9n\u00e9raux retenus**<br />\n&emsp;2.1 Calcul distribu\u00e9<br />\n&emsp;2.2 Transfert Learning<br />\n**3. D\u00e9ploiement de la solution en local**<br />\n&emsp;3.1 Environnement de travail<br />\n&emsp;3.2 Installation de Spark<br />\n&emsp;3.3 Installation des packages<br />\n&emsp;3.4 Import des librairies<br />\n&emsp;3.5 D\u00e9finition des PATH pour charger les images et enregistrer les r\u00e9sultats<br />\n&emsp;3.6 Cr\u00e9ation de la SparkSession<br />\n&emsp;3.7 Traitement des donn\u00e9es<br />\n&emsp;&emsp;3.7.1 Chargement des donn\u00e9es<br />\n&emsp;&emsp;3.7.2 Pr\u00e9paration du mod\u00e8le<br />\n&emsp;&emsp;3.7.3 D\u00e9finition du processus de chargement des images et application <br />\n&emsp;&emsp;&emsp;&emsp;&emsp;de leur featurisation \u00e0 travers l'utilisation de pandas UDF<br />\n&emsp;&emsp;3.7.4 Ex\u00e9cution des actions d'extractions de features<br />\n&emsp;3.8 Chargement des donn\u00e9es enregistr\u00e9es et validation du r\u00e9sultat<br />\n**4. D\u00e9ploiement de la solution sur le cloud**<br />\n&emsp;4.1 Choix du prestataire cloud : AWS<br />\n&emsp;4.2 Choix de la solution technique : EMR<br />\n&emsp;4.3 Choix de la solution de stockage des donn\u00e9es : Amazon S3<br />\n&emsp;4.4 Configuration de l'environnement de travail<br />\n&emsp;4.5 Upload de nos donn\u00e9es sur S3<br />\n&emsp;4.6 Configuration du serveur EMR<br />\n&emsp;&emsp;4.6.1 \u00c9tape 1 : Logiciels et \u00e9tapes<br />\n&emsp;&emsp;&emsp;4.6.1.1 Configuration des logiciels<br />\n&emsp;&emsp;&emsp;4.6.1.2 Modifier les param\u00e8tres du logiciel<br />\n&emsp;&emsp;4.6.2 \u00c9tape 2 : Mat\u00e9riel<br />\n&emsp;&emsp;4.6.3 \u00c9tape 3 : Param\u00e8tres de cluster g\u00e9n\u00e9raux<br />\n&emsp;&emsp;&emsp;4.6.3.1 Options g\u00e9n\u00e9rales<br />\n&emsp;&emsp;&emsp;4.6.3.2 Actions d'amor\u00e7age<br />\n&emsp;&emsp;4.6.4 \u00c9tape 4 : S\u00e9curit\u00e9<br />\n&emsp;&emsp;&emsp;4.6.4.1 Options de s\u00e9curit\u00e9<br />\n&emsp;4.7 Instanciation du serveur<br />\n&emsp;4.8 Cr\u00e9ation du tunnel SSH \u00e0 l'instance EC2 (Ma\u00eetre)<br />\n&emsp;&emsp;4.8.1 Cr\u00e9ation des autorisations sur les connexions entrantes<br />\n&emsp;&emsp;4.8.2 Cr\u00e9ation du tunnel ssh vers le Driver<br />\n&emsp;&emsp;4.8.3 Configuration de FoxyProxy<br />\n&emsp;&emsp;4.8.4 Acc\u00e8s aux applications du serveur EMR via le tunnel ssh<br />\n&emsp;4.9 Connexion au notebook JupyterHub<br />\n&emsp;4.10 Ex\u00e9cution du code<br />\n&emsp;&emsp;4.10.1 D\u00e9marrage de la session Spark<br />\n&emsp;&emsp;4.10.2 Installation des packages<br />\n&emsp;&emsp;4.10.3 Import des librairies<br />\n&emsp;&emsp;4.10.4 D\u00e9finition des PATH pour charger les images et enregistrer les r\u00e9sultats<br />\n&emsp;&emsp;4.10.5 Traitement des donn\u00e9es<br />\n&emsp;&emsp;&emsp;4.10.5.1 Chargement des donn\u00e9es<br />\n&emsp;&emsp;&emsp;4.10.5.2 Pr\u00e9paration du mod\u00e8le<br />\n&emsp;&emsp;&emsp;4.10.5.3 D\u00e9finition du processus de chargement des images<br />\n&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;et application de leur featurisation \u00e0 travers l'utilisation de pandas UDF<br />\n&emsp;&emsp;&emsp;4.10.5.4 Ex\u00e9cutions des actions d'extractions de features<br />\n&emsp;&emsp;4.10.6 Chargement des donn\u00e9es enregistr\u00e9es et validation du r\u00e9sultat<br />\n&emsp;4.11 Suivi de l'avancement des t\u00e2ches avec le Serveur d'Historique Spark<br />\n&emsp;4.12 R\u00e9siliation de l'instance EMR<br />\n&emsp;4.13 Cloner le serveur EMR (si besoin)<br />\n&emsp;4.14 Arborescence du serveur S3 \u00e0 la fin du projet<br />\n**5. Conclusion**"}, {"metadata": {"id": "ec2cee08"}, "id": "ec2cee08", "cell_type": "markdown", "source": "# 1. Pr\u00e9ambule\n\n## 1.1 Probl\u00e9matique\n\nLa tr\u00e8s jeune start-up de l'AgriTech, nomm\u00e9e \"**Fruits**!\", <br />\ncherche \u00e0 proposer des solutions innovantes pour la r\u00e9colte des fruits.\n\nLa volont\u00e9 de l\u2019entreprise est de pr\u00e9server la biodiversit\u00e9 des fruits <br />\nen permettant des traitements sp\u00e9cifiques pour chaque esp\u00e8ce de fruits <br />\nen d\u00e9veloppant des robots cueilleurs intelligents.\n\nLa start-up souhaite dans un premier temps se faire conna\u00eetre en mettant <br />\n\u00e0 disposition du grand public une application mobile qui permettrait aux <br />\nutilisateurs de prendre en photo un fruit et d'obtenir des informations sur ce fruit.\n\nPour la start-up, cette application permettrait de sensibiliser le grand public <br />\n\u00e0 la biodiversit\u00e9 des fruits et de mettre en place une premi\u00e8re version du moteur <br />\nde classification des images de fruits.\n\nDe plus, le d\u00e9veloppement de l\u2019application mobile permettra de construire <br />\nune premi\u00e8re version de l'architecture **Big Data** n\u00e9cessaire.\n\n## 1.2 Objectifs dans ce projet\n\n1. D\u00e9velopper une premi\u00e8re cha\u00eene de traitement des donn\u00e9es qui <br />\n   comprendra le **preprocessing** et une \u00e9tape de **r\u00e9duction de dimension**.\n2. Tenir compte du fait que <u>le volume de donn\u00e9es va augmenter <br />\n   tr\u00e8s rapidement</u> apr\u00e8s la livraison de ce projet, ce qui implique de:\n - D\u00e9ployer le traitement des donn\u00e9es dans un environnement **Big Data**\n - D\u00e9velopper les scripts en **pyspark** pour effectuer du **calcul distribu\u00e9**"}, {"metadata": {"id": "6b95e6ce"}, "id": "6b95e6ce", "cell_type": "markdown", "source": "## 1.3 D\u00e9roulement des \u00e9tapes du projet\n\nLe projet va \u00eatre r\u00e9alis\u00e9 en 2 temps, dans deux environnements diff\u00e9rents. <br />\nNous allons dans un premier temps d\u00e9velopper et ex\u00e9cuter notre code en local, <br />\nen travaillant sur un nombre limit\u00e9 d'images \u00e0 traiter.\n\nUne fois les choix techniques valid\u00e9s, nous d\u00e9ploierons notre solution <br />\ndans un environnement Big Data en mode distribu\u00e9.\n\n<u>Pour cette raison, ce projet sera divis\u00e9 en 3 parties</u>:\n1. Liste des choix techniques g\u00e9n\u00e9raux retenus\n2. D\u00e9ploiement de la solution en local\n3. D\u00e9ploiement de la solution dans le cloud"}, {"metadata": {"id": "f5b34029"}, "id": "f5b34029", "cell_type": "markdown", "source": "# 2. Choix techniques g\u00e9n\u00e9raux retenus"}, {"metadata": {"id": "32baf092"}, "id": "32baf092", "cell_type": "markdown", "source": "## 2.1 Calcul distribu\u00e9\n\nL\u2019\u00e9nonc\u00e9 du projet nous impose de d\u00e9velopper des scripts en **pyspark** <br />\nafin de <u>prendre en compte l\u2019augmentation tr\u00e8s rapide du volume <br />\nde donn\u00e9 apr\u00e8s la livraison du projet</u>.\n\nPour comprendre rapidement et simplement ce qu\u2019est **pyspark** <br />\net son principe de fonctionnement, nous vous conseillons de lire <br />\ncet article : [PySpark : Tout savoir sur la librairie Python](https://datascientest.com/pyspark)\n\n<u>Le d\u00e9but de l\u2019article nous dit ceci </u>:<br />\n\u00ab *Lorsque l\u2019on parle de traitement de bases de donn\u00e9es sur python, <br />\non pense imm\u00e9diatement \u00e0 la librairie pandas. Cependant, lorsqu\u2019on a <br />\naffaire \u00e0 des bases de donn\u00e9es trop massives, les calculs deviennent trop lents.<br />\nHeureusement, il existe une autre librairie python, assez proche <br />\nde pandas, qui permet de traiter des tr\u00e8s grandes quantit\u00e9s de donn\u00e9es : PySpark.<br />\nApache Spark est un framework open-source d\u00e9velopp\u00e9 par l\u2019AMPLab <br />\nde UC Berkeley permettant de traiter des bases de donn\u00e9es massives <br />\nen utilisant le calcul distribu\u00e9, technique qui consiste \u00e0 exploiter <br />\nplusieurs unit\u00e9s de calcul r\u00e9parties en clusters au profit d\u2019un seul <br />\nprojet afin de diviser le temps d\u2019ex\u00e9cution d\u2019une requ\u00eate.<br />\nSpark a \u00e9t\u00e9 d\u00e9velopp\u00e9 en Scala et est au meilleur de ses capacit\u00e9s <br />\ndans son langage natif. Cependant, la librairie PySpark propose de <br />\nl\u2019utiliser avec le langage Python, en gardant des performances <br />\nsimilaires \u00e0 des impl\u00e9mentations en Scala.<br />\nPyspark est donc une bonne alternative \u00e0 la librairie pandas lorsqu\u2019on <br />\ncherche \u00e0 traiter des jeux de donn\u00e9es trop volumineux qui entra\u00eenent <br />\ndes calculs trop chronophages.* \u00bb\n\nComme nous le constatons, **pySpark** est un moyen de communiquer <br />\navec **Spark** via le langage **Python**.<br />\n**Spark**, quant \u00e0 lui, est un outil qui permet de g\u00e9rer et de coordonner <br />\nl'ex\u00e9cution de t\u00e2ches sur des donn\u00e9es \u00e0 travers un groupe d'ordinateurs. <br />\n<u>Spark (ou Apache Spark) est un framework open source de calcul distribu\u00e9 <br />\nin-memory pour le traitement et l'analyse de donn\u00e9es massives</u>.\n\nUn autre [article tr\u00e8s int\u00e9ressant et beaucoup plus complet pour <br />\ncomprendre le **fonctionnement de Spark**](https://www.veonum.com/apache-spark-pour-les-nuls/), ainsi que le r\u00f4le <br />\ndes **Spark Session** que nous utiliserons dans ce projet.\n\n<u>Voici \u00e9galement un extrait</u>:\n\n*Les applications Spark se composent d\u2019un pilote (\u00ab\u202fdriver process\u202f\u00bb) <br />\net de plusieurs ex\u00e9cuteurs (\u00ab\u202fexecutor processes\u202f\u00bb). Il peut \u00eatre configur\u00e9 <br />\npour \u00eatre lui-m\u00eame l\u2019ex\u00e9cuteur (local mode) ou en utiliser autant que <br />\nn\u00e9cessaire pour traiter l\u2019application, Spark prenant en charge la mise <br />\n\u00e0 l\u2019\u00e9chelle automatique par une configuration d\u2019un nombre minimum <br />\net maximum d\u2019ex\u00e9cuteurs.*\n\n![Sch\u00e9ma de Spark](img/spark-schema.png)\n\n*Le driver (parfois appel\u00e9 \u00ab\u202fSpark Session\u202f\u00bb) distribue et planifie <br />\nles t\u00e2ches entre les diff\u00e9rents ex\u00e9cuteurs qui les ex\u00e9cutent et permettent <br />\nun traitement r\u00e9parti. Il est le responsable de l\u2019ex\u00e9cution du code <br />\nsur les diff\u00e9rentes machines.\n\nChaque ex\u00e9cuteur est un processus Java Virtual Machine (JVM) distinct <br />\ndont il est possible de configurer le nombre de CPU et la quantit\u00e9 de <br />\nm\u00e9moire qui lui est allou\u00e9. <br />\nUne seule t\u00e2che peut traiter un fractionnement de donn\u00e9es \u00e0 la fois.*\n\nDans les deux environnements (Local et Cloud) nous utiliserons donc **Spark** <br />\net nous l\u2019exploiterons \u00e0 travers des scripts python gr\u00e2ce \u00e0 **PySpark**.\n\nDans la <u>version locale</u> de notre script nous **simulerons <br />\nle calcul distribu\u00e9** afin de valider que notre solution fonctionne.<br />\nDans la <u>version cloud</u> nous **r\u00e9aliserons les op\u00e9rations sur un cluster de machine**."}, {"metadata": {"id": "5364c9f9"}, "id": "5364c9f9", "cell_type": "markdown", "source": "## 2.2 Transfert Learning\n\nL'\u00e9nonc\u00e9 du projet nous demande \u00e9galement de <br />\nr\u00e9aliser une premi\u00e8re cha\u00eene de traitement <br />\ndes donn\u00e9es qui comprendra le preprocessing et <br />\nune \u00e9tape de r\u00e9duction de dimension.\n\nIl est \u00e9galement pr\u00e9cis\u00e9 qu'il n'est pas n\u00e9cessaire <br />\nd'entra\u00eener un mod\u00e8le pour le moment.\n\nNous d\u00e9cidons de partir sur une solution de **transfert learning**.\n\nSimplement, le **transfert learning** consiste <br />\n\u00e0 utiliser la connaissance d\u00e9j\u00e0 acquise <br />\npar un mod\u00e8le entra\u00een\u00e9 (ici **MobileNetV2**) pour <br />\nl'adapter \u00e0 notre probl\u00e9matique.\n\nNous allons fournir au mod\u00e8le nos images, et nous allons <br />\n<u>r\u00e9cup\u00e9rer l'avant derni\u00e8re couche</u> du mod\u00e8le.<br />\nEn effet la derni\u00e8re couche de mod\u00e8le est une couche softmax <br />\nqui permet la classification des images ce que nous ne <br />\nsouhaitons pas dans ce projet.\n\nL'avant derni\u00e8re couche correspond \u00e0 un **vecteur <br />\nr\u00e9duit** de dimension (1,1,1280).\n\nCela permettra de r\u00e9aliser une premi\u00e8re version du moteur <br />\npour la classification des images des fruits.\n\n**MobileNetV2** a \u00e9t\u00e9 retenu pour sa <u>rapidit\u00e9 d'ex\u00e9cution</u>, <br />\nparticuli\u00e8rement adapt\u00e9e pour le traitement d'un gros volume <br />\nde donn\u00e9es ainsi que la <u>faible dimensionnalit\u00e9 du vecteur <br />\nde caract\u00e9ristique en sortie</u> (1,1,1280)"}, {"metadata": {"id": "1e89a2da"}, "id": "1e89a2da", "cell_type": "markdown", "source": "# 3. D\u00e9ploiement de la solution en local\n\n\n## 3.1 Environnement de travail\n\nPour des raisons de simplicit\u00e9, nous d\u00e9veloppons dans un environnement <br />\nLinux Unbuntu (ex\u00e9cut\u00e9 depuis une machine Windows dans une machine virtuelle)\n* Pour installer une machine virtuelle :  https://www.malekal.com/meilleurs-logiciels-de-machine-virtuelle-gratuits-ou-payants/\n\n## 3.2 Installation de Spark\n\n[La premi\u00e8re \u00e9tape consiste \u00e0 installer Spark ](https://computingforgeeks.com/how-to-install-apache-spark-on-ubuntu-debian/)\n\n## 3.3 Installation des packages\n\n<u>On installe ensuite \u00e0 l'aide de la commande **pip** <br />\nles packages qui nous seront n\u00e9cessaires</u> :"}, {"metadata": {"scrolled": true, "colab": {"base_uri": "https://localhost:8080/"}, "id": "728d9256", "outputId": "d15e75a8-e1ea-4285-f3cb-8b801d400976", "trusted": false}, "id": "728d9256", "cell_type": "code", "source": "!pip install pandas pillow tensorflow pyspark pyarrow", "execution_count": 6, "outputs": [{"output_type": "stream", "text": "Requirement already satisfied: pandas in /opt/mamba/lib/python3.9/site-packages (1.4.4)\nRequirement already satisfied: pillow in /opt/mamba/lib/python3.9/site-packages (10.2.0)\nCollecting tensorflow\n  Downloading tensorflow-2.16.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\nCollecting pyspark\n  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting pyarrow\n  Downloading pyarrow-16.1.0-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/mamba/lib/python3.9/site-packages (from pandas) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/mamba/lib/python3.9/site-packages (from pandas) (2024.1)\nRequirement already satisfied: numpy>=1.18.5 in /opt/mamba/lib/python3.9/site-packages (from pandas) (1.26.4)\nCollecting absl-py>=1.0.0 (from tensorflow)\n  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\nCollecting astunparse>=1.6.0 (from tensorflow)\n  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\nCollecting flatbuffers>=23.5.26 (from tensorflow)\n  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\nCollecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n  Downloading gast-0.5.4-py3-none-any.whl.metadata (1.3 kB)\nCollecting google-pasta>=0.1.1 (from tensorflow)\n  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\nCollecting h5py>=3.10.0 (from tensorflow)\n  Downloading h5py-3.11.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\nCollecting libclang>=13.0.0 (from tensorflow)\n  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\nCollecting ml-dtypes~=0.3.1 (from tensorflow)\n  Downloading ml_dtypes-0.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\nCollecting opt-einsum>=2.3.2 (from tensorflow)\n  Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\nRequirement already satisfied: packaging in /opt/mamba/lib/python3.9/site-packages (from tensorflow) (23.2)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/mamba/lib/python3.9/site-packages (from tensorflow) (4.25.2)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/mamba/lib/python3.9/site-packages (from tensorflow) (2.31.0)\nRequirement already satisfied: setuptools in /opt/mamba/lib/python3.9/site-packages (from tensorflow) (69.0.3)\nRequirement already satisfied: six>=1.12.0 in /opt/mamba/lib/python3.9/site-packages (from tensorflow) (1.16.0)\nCollecting termcolor>=1.1.0 (from tensorflow)\n  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/mamba/lib/python3.9/site-packages (from tensorflow) (4.9.0)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/mamba/lib/python3.9/site-packages (from tensorflow) (1.16.0)\nCollecting grpcio<2.0,>=1.24.3 (from tensorflow)\n  Downloading grpcio-1.64.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\nCollecting tensorboard<2.17,>=2.16 (from tensorflow)\n  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\nCollecting keras>=3.0.0 (from tensorflow)\n  Downloading keras-3.3.3-py3-none-any.whl.metadata (5.7 kB)\nCollecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n  Downloading tensorflow_io_gcs_filesystem-0.37.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\nCollecting py4j==0.10.9.7 (from pyspark)\n  Downloading py4j-0.10.9.7-py2.py3-none-any.whl.metadata (1.5 kB)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/mamba/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\nCollecting rich (from keras>=3.0.0->tensorflow)\n  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\nCollecting namex (from keras>=3.0.0->tensorflow)\n  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\nCollecting optree (from keras>=3.0.0->tensorflow)\n  Downloading optree-0.11.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (45 kB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /opt/mamba/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/mamba/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/mamba/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.16)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/mamba/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\nCollecting markdown>=2.6.8 (from tensorboard<2.17,>=2.16->tensorflow)\n  Downloading Markdown-3.6-py3-none-any.whl.metadata (7.0 kB)\nCollecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.17,>=2.16->tensorflow)\n  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\nCollecting werkzeug>=1.0.1 (from tensorboard<2.17,>=2.16->tensorflow)\n  Downloading werkzeug-3.0.3-py3-none-any.whl.metadata (3.7 kB)\nRequirement already satisfied: importlib-metadata>=4.4 in /opt/mamba/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.17,>=2.16->tensorflow) (7.0.1)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/mamba/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\nCollecting markdown-it-py>=2.2.0 (from rich->keras>=3.0.0->tensorflow)\n  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/mamba/lib/python3.9/site-packages (from rich->keras>=3.0.0->tensorflow) (2.17.2)\nRequirement already satisfied: zipp>=0.5 in /opt/mamba/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.17,>=2.16->tensorflow) (3.17.0)\nCollecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow)\n  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\nDownloading tensorflow-2.16.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m200.5/200.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading pyarrow-16.1.0-cp39-cp39-manylinux_2_28_x86_64.whl (40.8 MB)\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\nDownloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\nDownloading gast-0.5.4-py3-none-any.whl (19 kB)\nDownloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading grpcio-1.64.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.6 MB)\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading h5py-3.11.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading keras-3.3.3-py3-none-any.whl (1.1 MB)\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading ml_dtypes-0.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\nDownloading Markdown-3.6-py3-none-any.whl (105 kB)\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading werkzeug-3.0.3-py3-none-any.whl (227 kB)\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m227.3/227.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading namex-0.0.8-py3-none-any.whl (5.8 kB)\nDownloading optree-0.11.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (311 kB)\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m311.9/311.9 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading rich-13.7.1-py3-none-any.whl (240 kB)\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\nBuilding wheels for collected packages: pyspark\n  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488493 sha256=5155a047a1b03454d4b0a87cd8dbbab32bc35f6f6ec71be5fe625c5807860577\n  Stored in directory: /home/jovyan/.cache/pip/wheels/92/09/11/aa01d01a7f005fda8a66ad71d2be7f8aa341bddafb27eee3c7\nSuccessfully built pyspark\nInstalling collected packages: py4j, namex, libclang, flatbuffers, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, pyspark, pyarrow, optree, opt-einsum, ml-dtypes, mdurl, h5py, grpcio, google-pasta, gast, astunparse, absl-py, markdown-it-py, markdown, tensorboard, rich, keras, tensorflow\nSuccessfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.5.4 google-pasta-0.2.0 grpcio-1.64.1 h5py-3.11.0 keras-3.3.3 libclang-18.1.1 markdown-3.6 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.3.2 namex-0.0.8 opt-einsum-3.3.0 optree-0.11.0 py4j-0.10.9.7 pyarrow-16.1.0 pyspark-3.5.1 rich-13.7.1 tensorboard-2.16.2 tensorboard-data-server-0.7.2 tensorflow-2.16.1 tensorflow-io-gcs-filesystem-0.37.0 termcolor-2.4.0 werkzeug-3.0.3\n", "name": "stdout"}]}, {"metadata": {"id": "33a43845"}, "id": "33a43845", "cell_type": "markdown", "source": "## 3.4 Import des librairies"}, {"metadata": {"id": "a5c0c74f", "trusted": false}, "id": "a5c0c74f", "cell_type": "code", "source": "import pandas as pd\nfrom PIL import Image\nimport numpy as np\nimport io\nimport os\n\nimport tensorflow as tf\nfrom tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras import Model\nfrom pyspark.sql.functions import col, pandas_udf, PandasUDFType, element_at, split\nfrom pyspark.sql import SparkSession", "execution_count": 7, "outputs": []}, {"metadata": {"id": "661ff67c"}, "id": "661ff67c", "cell_type": "markdown", "source": "## 3.5 D\u00e9finition des PATH pour charger les images <br /> et enregistrer les r\u00e9sultats\n\nDans cette version locale nous partons du principe que les donn\u00e9es <br />\nsont stock\u00e9es dans le m\u00eame r\u00e9pertoire que le notebook.<br />\nNous n'utilisons qu'un extrait de **300 images** \u00e0 traiter dans cette <br />\npremi\u00e8re version en local.<br />\nL'extrait des images \u00e0 charger est stock\u00e9e dans le dossier **Test1**.<br />\nNous enregistrerons le r\u00e9sultat de notre traitement <br />\ndans le dossier \"**Results_Local**\""}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "PMi07hKonO0h", "outputId": "20e2f2d2-c507-46cb-dbff-97598589a6d0", "trusted": false}, "id": "PMi07hKonO0h", "cell_type": "code", "source": "PATH = '/content/drive/MyDrive/FORMATION DATASCIENTIST OC - Lucas GAMBA/Projet 9'\nPATH_Data = PATH+'/data/Test1'\nPATH_Result = PATH+'/data/Results'\nprint('PATH:        '+\\\n      PATH+'\\nPATH_Data:   '+\\\n      PATH_Data+'\\nPATH_Result: '+PATH_Result)", "execution_count": 14, "outputs": [{"output_type": "stream", "name": "stdout", "text": "PATH:        /content/drive/MyDrive/FORMATION DATASCIENTIST OC - Lucas GAMBA/Projet 9\nPATH_Data:   /content/drive/MyDrive/FORMATION DATASCIENTIST OC - Lucas GAMBA/Projet 9/data/Test1\nPATH_Result: /content/drive/MyDrive/FORMATION DATASCIENTIST OC - Lucas GAMBA/Projet 9/data/Results\n"}]}, {"metadata": {"id": "da5e637a"}, "id": "da5e637a", "cell_type": "markdown", "source": "## 3.6 Cr\u00e9ation de la SparkSession\n\nL\u2019application Spark est contr\u00f4l\u00e9e gr\u00e2ce \u00e0 un processus de pilotage (driver process) appel\u00e9 **SparkSession**. <br />\n<u>Une instance de **SparkSession** est la fa\u00e7on dont Spark ex\u00e9cute les fonctions d\u00e9finies par l\u2019utilisateur <br />\ndans l\u2019ensemble du cluster</u>. <u>Une SparkSession correspond toujours \u00e0 une application Spark</u>.\n\n<u>Ici nous cr\u00e9ons une session spark en sp\u00e9cifiant dans l'ordre</u> :\n 1. un **nom pour l'application**, qui sera affich\u00e9e dans l'interface utilisateur Web Spark \"**P8**\"\n 2. que l'application doit s'ex\u00e9cuter **localement**. <br />\n   Nous ne d\u00e9finissons pas le nombre de c\u0153urs \u00e0 utiliser (comme .master('local[4]) pour 4 c\u0153urs \u00e0 utiliser), <br />\n   nous utiliserons donc tous les c\u0153urs disponibles dans notre processeur.<br />\n 3. une option de configuration suppl\u00e9mentaire permettant d'utiliser le **format \"parquet\"** <br />\n   que nous utiliserons pour enregistrer et charger le r\u00e9sultat de notre travail.\n 4. vouloir **obtenir une session spark** existante ou si aucune n'existe, en cr\u00e9er une nouvelle"}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "b7bea157", "outputId": "74efc963-09a9-4132-914a-acf61b49990b", "trusted": false}, "id": "b7bea157", "cell_type": "code", "source": "spark = (SparkSession\n             .builder\n             .appName('P8')\n             .master('local')\n             .config(\"spark.sql.parquet.writeLegacyFormat\", 'true')\n             .getOrCreate()\n)", "execution_count": 8, "outputs": [{"output_type": "error", "ename": "PySparkRuntimeError", "evalue": "[JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mPySparkRuntimeError\u001b[0m                       Traceback (most recent call last)", "\u001b[0;32m<ipython-input-8-24b195a1ccd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m spark = (SparkSession\n\u001b[0m\u001b[1;32m      2\u001b[0m              \u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m              \u001b[0;34m.\u001b[0m\u001b[0mappName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'P8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m              \u001b[0;34m.\u001b[0m\u001b[0mmaster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'local'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m              \u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"spark.sql.parquet.writeLegacyFormat\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'true'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/mamba/lib/python3.9/site-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    495\u001b[0m                         \u001b[0msparkConf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m                     \u001b[0;31m# This SparkContext may be an existing one.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m                     \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparkConf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m                     \u001b[0;31m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m                     \u001b[0;31m# by all sessions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/mamba/lib/python3.9/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[0;34m(cls, conf)\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mSparkConf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/mamba/lib/python3.9/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n\u001b[1;32m    199\u001b[0m             )\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             self._do_init(\n", "\u001b[0;32m/opt/mamba/lib/python3.9/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgateway\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlaunch_gateway\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjvm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/mamba/lib/python3.9/site-packages/pyspark/java_gateway.py\u001b[0m in \u001b[0;36mlaunch_gateway\u001b[0;34m(conf, popen_kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn_info_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                 raise PySparkRuntimeError(\n\u001b[0m\u001b[1;32m    108\u001b[0m                     \u001b[0merror_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"JAVA_GATEWAY_EXITED\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                     \u001b[0mmessage_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mPySparkRuntimeError\u001b[0m: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number."]}]}, {"metadata": {"id": "5c8b53ac"}, "id": "5c8b53ac", "cell_type": "markdown", "source": "<u>Nous cr\u00e9ons \u00e9galement la variable \"**sc**\" qui est un **SparkContext** issue de la variable **spark**</u> :"}, {"metadata": {"id": "14aeccb1", "trusted": false}, "id": "14aeccb1", "cell_type": "code", "source": "sc = spark.sparkContext", "execution_count": 9, "outputs": [{"output_type": "error", "ename": "NameError", "evalue": "name 'spark' is not defined", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)", "\u001b[0;32m<ipython-input-9-ed5a16d870c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"]}]}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 196}, "id": "-NnuneWSmBgJ", "outputId": "76b78415-53b9-410a-bbbe-5abcb4f36cc7", "trusted": false}, "id": "-NnuneWSmBgJ", "cell_type": "code", "source": "sc", "execution_count": 10, "outputs": [{"output_type": "execute_result", "execution_count": 10, "data": {"text/plain": "''"}, "metadata": {}}]}, {"metadata": {"id": "5a086010"}, "id": "5a086010", "cell_type": "markdown", "source": "<u>Affichage des informations de Spark en cours d'execution</u> :"}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 219}, "id": "e97bf13b", "outputId": "67107bb7-5d84-4ba1-d666-e331cfbf4fc7", "trusted": false}, "id": "e97bf13b", "cell_type": "code", "source": "spark", "execution_count": 11, "outputs": [{"output_type": "error", "ename": "NameError", "evalue": "name 'spark' is not defined", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)", "\u001b[0;32m<ipython-input-11-84901cd22f32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"]}]}, {"metadata": {"id": "195a88b0"}, "id": "195a88b0", "cell_type": "markdown", "source": "## 3.7 Traitement des donn\u00e9es\n\n<u>Dans la suite de notre flux de travail, <br />\nnous allons successivement</u> :\n1. Pr\u00e9parer nos donn\u00e9es\n    1. Importer les images dans un dataframe **pandas UDF**\n    2. Associer aux images leur **label**\n    3. Pr\u00e9processer en **redimensionnant nos images pour <br />\n       qu'elles soient compatibles avec notre mod\u00e8le**\n2. Pr\u00e9parer notre mod\u00e8le\n    1. Importer le mod\u00e8le **MobileNetV2**\n    2. Cr\u00e9er un **nouveau mod\u00e8le** d\u00e9pourvu de la derni\u00e8re couche de MobileNetV2\n3. D\u00e9finir le processus de chargement des images et l'application <br />\n   de leur featurisation \u00e0 travers l'utilisation de pandas UDF\n3. Ex\u00e9cuter les actions d'extraction de features\n4. Enregistrer le r\u00e9sultat de nos actions\n5. Tester le bon fonctionnement en chargeant les donn\u00e9es enregistr\u00e9es\n\n\n"}, {"metadata": {"id": "386fe0bc"}, "id": "386fe0bc", "cell_type": "markdown", "source": "### 3.7.1 Chargement des donn\u00e9es\n\nLes images sont charg\u00e9es au format binaire, ce qui offre, <br />\nplus de souplesse dans la fa\u00e7on de pr\u00e9traiter les images.\n\nAvant de charger les images, nous sp\u00e9cifions que nous voulons charger <br />\nuniquement les fichiers dont l'extension est **jpg**.\n\nNous indiquons \u00e9galement de charger tous les objets possibles contenus <br />\ndans les sous-dossiers du dossier communiqu\u00e9."}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 35}, "id": "PKhgqTOomaJe", "outputId": "afe93ef0-6954-4a49-e7ef-a91dd4412251", "trusted": false}, "id": "PKhgqTOomaJe", "cell_type": "code", "source": "PATH_Data", "execution_count": 10, "outputs": [{"output_type": "execute_result", "data": {"text/plain": "'/content/data/Test1'", "application/vnd.google.colaboratory.intrinsic+json": {"type": "string"}}, "metadata": {}, "execution_count": 10}]}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "KAkfpYiommdx", "outputId": "7dbaf655-fef9-44f2-ebb3-dd91c7e6d5bc", "trusted": false}, "id": "KAkfpYiommdx", "cell_type": "code", "source": "from google.colab import drive\ndrive.mount('/content/drive')", "execution_count": 11, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Mounted at /content/drive\n"}]}, {"metadata": {"id": "e68e53b9", "trusted": false}, "id": "e68e53b9", "cell_type": "code", "source": "images = spark.read.format(\"binaryFile\") \\\n  .option(\"pathGlobFilter\", \"*.jpg\") \\\n  .option(\"recursiveFileLookup\", \"true\") \\\n  .load(PATH_Data)", "execution_count": 15, "outputs": []}, {"metadata": {"id": "645faeaf"}, "id": "645faeaf", "cell_type": "markdown", "source": "<u>Affichage des 5 premi\u00e8res images contenant</u> :\n - le path de l'image\n - la date et heure de sa derni\u00e8re modification\n - sa longueur\n - son contenu encod\u00e9 en valeur hexad\u00e9cimal"}, {"metadata": {"id": "863981e5"}, "id": "863981e5", "cell_type": "markdown", "source": "<u>Je ne conserve que le **path** de l'image et j'ajoute <br />\n    une colonne contenant les **labels** de chaque image</u> :"}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "a08b0494", "outputId": "09aff542-89aa-474e-d4e6-a9f499f16b37", "trusted": false}, "id": "a08b0494", "cell_type": "code", "source": "images = images.withColumn('label', element_at(split(images['path'], '/'),-2))\nprint(images.printSchema())\nprint(images.select('path','label').show(5,False))", "execution_count": 16, "outputs": [{"output_type": "stream", "name": "stdout", "text": "root\n |-- path: string (nullable = true)\n |-- modificationTime: timestamp (nullable = true)\n |-- length: long (nullable = true)\n |-- content: binary (nullable = true)\n |-- label: string (nullable = true)\n\nNone\n+-------------------------------------------------------------------------------------------------------------------+------------+\n|path                                                                                                               |label       |\n+-------------------------------------------------------------------------------------------------------------------+------------+\n|file:/content/drive/MyDrive/FORMATION DATASCIENTIST OC - Lucas GAMBA/Projet 9/data/Test1/Potato White/r2_68_100.jpg|Potato White|\n|file:/content/drive/MyDrive/FORMATION DATASCIENTIST OC - Lucas GAMBA/Projet 9/data/Test1/Potato White/r2_71_100.jpg|Potato White|\n|file:/content/drive/MyDrive/FORMATION DATASCIENTIST OC - Lucas GAMBA/Projet 9/data/Test1/Potato White/r2_70_100.jpg|Potato White|\n|file:/content/drive/MyDrive/FORMATION DATASCIENTIST OC - Lucas GAMBA/Projet 9/data/Test1/Potato White/r2_67_100.jpg|Potato White|\n|file:/content/drive/MyDrive/FORMATION DATASCIENTIST OC - Lucas GAMBA/Projet 9/data/Test1/Potato White/r2_79_100.jpg|Potato White|\n+-------------------------------------------------------------------------------------------------------------------+------------+\nonly showing top 5 rows\n\nNone\n"}]}, {"metadata": {"id": "83d47705"}, "id": "83d47705", "cell_type": "markdown", "source": "### 3.7.2 Pr\u00e9paration du mod\u00e8le\n\nJe vais utiliser la technique du **transfert learning** pour extraire les features des images.<br />\nJ'ai choisi d'utiliser le mod\u00e8le **MobileNetV2** pour sa rapidit\u00e9 d'ex\u00e9cution compar\u00e9e <br />\n\u00e0 d'autres mod\u00e8les comme *VGG16* par exemple.\n\nPour en savoir plus sur la conception et le fonctionnement de MobileNetV2, <br />\nje vous invite \u00e0 lire [cet article](https://towardsdatascience.com/review-mobilenetv2-light-weight-model-image-classification-8febb490e61c).\n\n<u>Voici le sch\u00e9ma de son architecture globale</u> :\n\n![Architecture de MobileNetV2](img/mobilenetv2_architecture.png)\n\nIl existe une derni\u00e8re couche qui sert \u00e0 classer les images <br />\nselon 1000 cat\u00e9gories que nous ne voulons pas utiliser.<br />\nL'id\u00e9e dans ce projet est de r\u00e9cup\u00e9rer le **vecteur de caract\u00e9ristiques <br />\nde dimensions (1,1,1280)** qui servira, plus tard, au travers d'un moteur <br />\nde classification \u00e0 reconnaitre les diff\u00e9rents fruits du jeu de donn\u00e9es.\n\nComme d'autres mod\u00e8les similaires, **MobileNetV2**, lorsqu'on l'utilise <br />\nen incluant toutes ses couches, attend obligatoirement des images <br />\nde dimension (224,224,3). Nos images \u00e9tant toutes de dimension (100,100,3), <br />\nnous devrons simplement les **redimensionner** avant de les confier au mod\u00e8le.\n\n<u>Dans l'odre</u> :\n 1. Nous chargeons le mod\u00e8le **MobileNetV2** avec les poids **pr\u00e9calcul\u00e9s** <br />\n    issus d'**imagenet** et en sp\u00e9cifiant le format de nos images en entr\u00e9e\n 2. Nous cr\u00e9ons un nouveau mod\u00e8le avec:\n  - <u>en entr\u00e9e</u> : l'entr\u00e9e du mod\u00e8le MobileNetV2\n  - <u>en sortie</u> : l'avant derni\u00e8re couche du mod\u00e8le MobileNetV2"}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "9cdd9bdf", "outputId": "681183ae-53cb-497f-dd5c-6a6a76f7c689", "trusted": false}, "id": "9cdd9bdf", "cell_type": "code", "source": "model = MobileNetV2(weights='imagenet',\n                    include_top=True,\n                    input_shape=(224, 224, 3))", "execution_count": 17, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224.h5\n14536120/14536120 [==============================] - 0s 0us/step\n"}]}, {"metadata": {"id": "99d6b68d", "trusted": false}, "id": "99d6b68d", "cell_type": "code", "source": "new_model = Model(inputs=model.input,\n                  outputs=model.layers[-2].output)", "execution_count": 18, "outputs": []}, {"metadata": {"id": "7b197379"}, "id": "7b197379", "cell_type": "markdown", "source": "Affichage du r\u00e9sum\u00e9 de notre nouveau mod\u00e8le o\u00f9 nous constatons <br />\nque <u>nous r\u00e9cup\u00e9rons bien en sortie un vecteur de dimension (1, 1, 1280)</u> :"}, {"metadata": {"id": "e8207725", "trusted": false}, "id": "e8207725", "cell_type": "code", "source": "new_model.summary()", "execution_count": null, "outputs": []}, {"metadata": {"id": "2a0adcf5"}, "id": "2a0adcf5", "cell_type": "markdown", "source": "Tous les workeurs doivent pouvoir acc\u00e9der au mod\u00e8le ainsi qu'\u00e0 ses poids. <br />\nUne bonne pratique consiste \u00e0 charger le mod\u00e8le sur le driver puis \u00e0 diffuser <br />\nensuite les poids aux diff\u00e9rents workeurs."}, {"metadata": {"id": "1cc53ff0", "trusted": false}, "id": "1cc53ff0", "cell_type": "code", "source": "brodcast_weights = sc.broadcast(new_model.get_weights())", "execution_count": 20, "outputs": []}, {"metadata": {"id": "8bc0e34e"}, "id": "8bc0e34e", "cell_type": "markdown", "source": "<u>Mettons cela sous forme de fonction</u> :"}, {"metadata": {"id": "3fd51ba9", "trusted": false}, "id": "3fd51ba9", "cell_type": "code", "source": "def model_fn():\n    \"\"\"\n    Returns a MobileNetV2 model with top layer removed\n    and broadcasted pretrained weights.\n    \"\"\"\n    model = MobileNetV2(weights='imagenet',\n                        include_top=True,\n                        input_shape=(224, 224, 3))\n    for layer in model.layers:\n        layer.trainable = False\n    new_model = Model(inputs=model.input,\n                  outputs=model.layers[-2].output)\n    new_model.set_weights(brodcast_weights.value)\n    return new_model", "execution_count": 22, "outputs": []}, {"metadata": {"id": "e5620876"}, "id": "e5620876", "cell_type": "markdown", "source": "### 3.7.3 D\u00e9finition du processus de chargement des images et application <br/>de leur featurisation \u00e0 travers l'utilisation de pandas UDF\n\nCe notebook d\u00e9finit la logique par \u00e9tapes, jusqu'\u00e0 Pandas UDF.\n\n<u>L'empilement des appels est la suivante</u> :\n\n- Pandas UDF\n  - featuriser une s\u00e9rie d'images pd.Series\n   - pr\u00e9traiter une image"}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "dc4e5f69", "outputId": "8a9f7e00-816e-4bf0-964d-60cbadd1a69e", "trusted": false}, "id": "dc4e5f69", "cell_type": "code", "source": "def preprocess(content):\n    \"\"\"\n    Preprocesses raw image bytes for prediction.\n    \"\"\"\n    img = Image.open(io.BytesIO(content)).resize([224, 224])\n    arr = img_to_array(img)\n    return preprocess_input(arr)\n\ndef featurize_series(model, content_series):\n    \"\"\"\n    Featurize a pd.Series of raw images using the input model.\n    :return: a pd.Series of image features\n    \"\"\"\n    input = np.stack(content_series.map(preprocess))\n    preds = model.predict(input)\n    # For some layers, output features will be multi-dimensional tensors.\n    # We flatten the feature tensors to vectors for easier storage in Spark DataFrames.\n    output = [p.flatten() for p in preds]\n    return pd.Series(output)\n\n@pandas_udf('array<float>', PandasUDFType.SCALAR_ITER)\ndef featurize_udf(content_series_iter):\n    '''\n    This method is a Scalar Iterator pandas UDF wrapping our featurization function.\n    The decorator specifies that this returns a Spark DataFrame column of type ArrayType(FloatType).\n\n    :param content_series_iter: This argument is an iterator over batches of data, where each batch\n                              is a pandas Series of image data.\n    '''\n    # With Scalar Iterator pandas UDFs, we can load the model once and then re-use it\n    # for multiple data batches.  This amortizes the overhead of loading big models.\n    model = model_fn()\n    for content_series in content_series_iter:\n        yield featurize_series(model, content_series)", "execution_count": 23, "outputs": [{"output_type": "stream", "name": "stderr", "text": "/usr/local/lib/python3.10/dist-packages/pyspark/sql/pandas/functions.py:407: UserWarning: In Python 3.6+ and Spark 3.0+, it is preferred to specify type hints for pandas UDF instead of specifying pandas UDF type which will be deprecated in the future releases. See SPARK-28264 for more details.\n  warnings.warn(\n"}]}, {"metadata": {"id": "2bdf2ef9"}, "id": "2bdf2ef9", "cell_type": "markdown", "source": "### 3.7.4 Ex\u00e9cution des actions d'extraction de features\n\nLes Pandas UDF, sur de grands enregistrements (par exemple, de tr\u00e8s grandes images), <br />\npeuvent rencontrer des erreurs de type Out Of Memory (OOM).<br />\nSi vous rencontrez de telles erreurs dans la cellule ci-dessous, <br />\nessayez de r\u00e9duire la taille du lot Arrow via 'maxRecordsPerBatch'\n\nJe n'utiliserai pas cette commande dans ce projet <br />\net je laisse donc la commande en commentaire."}, {"metadata": {"id": "1f30d28c", "trusted": false}, "id": "1f30d28c", "cell_type": "code", "source": "# spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"1024\")", "execution_count": null, "outputs": []}, {"metadata": {"id": "70f8f95d"}, "id": "70f8f95d", "cell_type": "markdown", "source": "Nous pouvons maintenant ex\u00e9cuter la featurisation sur l'ensemble de notre DataFrame Spark.<br />\n<u>REMARQUE</u> : Cela peut prendre beaucoup de temps, tout d\u00e9pend du volume de donn\u00e9es \u00e0 traiter. <br />\n\nNotre jeu de donn\u00e9es de **Test** contient **22819 images**. <br />\nCependant, dans l'ex\u00e9cution en mode **local**, <br />\nnous <u>traiterons un ensemble r\u00e9duit de **330 images**</u>."}, {"metadata": {"id": "69c1767c", "trusted": false}, "id": "69c1767c", "cell_type": "code", "source": "features_df = images.repartition(20).select(col(\"path\"),\n                                            col(\"label\"),\n                                            featurize_udf(\"content\").alias(\"features\")\n                                           )", "execution_count": 24, "outputs": []}, {"metadata": {"id": "jvGZ2fBWyqSG"}, "id": "jvGZ2fBWyqSG", "cell_type": "markdown", "source": "### 3.7.5 R\u00e9duction de dimension"}, {"metadata": {"id": "j4rInJnD6c9C"}, "id": "j4rInJnD6c9C", "cell_type": "markdown", "source": "Nous allons r\u00e9duire la taille des caract\u00e9ristiques d'images en appliquant une PCA. Pour cela, nous convertir le contenu de la colonne features tout juste cr\u00e9\u00e9e pour analyser le nombre de composante n\u00e9cessaire pour conserver 99.9% de la variance."}, {"metadata": {"id": "ClYC0ptQ7OeN"}, "id": "ClYC0ptQ7OeN", "cell_type": "markdown", "source": "On importe les package pyspark pour le PCA et la vectorisation."}, {"metadata": {"id": "mWjS-epYymDe", "trusted": false}, "id": "mWjS-epYymDe", "cell_type": "code", "source": "from pyspark.ml.feature import PCA\nfrom pyspark.ml.linalg import Vectors, VectorUDT\nfrom pyspark.sql.functions import udf", "execution_count": 38, "outputs": []}, {"metadata": {"id": "Y-E1xv4B7bGv"}, "id": "Y-E1xv4B7bGv", "cell_type": "markdown", "source": "On vectorise puis fit la pca."}, {"metadata": {"id": "fiaTNztoy01k", "trusted": false}, "id": "fiaTNztoy01k", "cell_type": "code", "source": "# Step 2: Convert features to a Vector column for PCA\nto_vector_udf = udf(lambda r: Vectors.dense(r), VectorUDT())\nfeatures_vector_df = features_df.withColumn(\"features_vector\", to_vector_udf(col(\"features\")))\n\n# Step 3: Apply PCA using PySpark\nn_components = 500\npca = PCA(k=n_components, inputCol=\"features_vector\", outputCol=\"pca_features\")\npca_model = pca.fit(features_vector_df)", "execution_count": 40, "outputs": []}, {"metadata": {"id": "17iT9rOF7e5l"}, "id": "17iT9rOF7e5l", "cell_type": "markdown", "source": "On \u00e9valut le nombre de composante."}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "uBpmjt0-5TGu", "outputId": "5565e265-999d-4ac8-9b88-0b1132e78bd5", "trusted": false}, "id": "uBpmjt0-5TGu", "cell_type": "code", "source": "# Calculate explained variance\nexplained_variance = np.cumsum(pca_model.explainedVariance.toArray())\n\n# Determine number of components to explain desired variance (e.g., 95%)\ndesired_variance = 0.999\nn_components = np.argmax(explained_variance >= desired_variance) + 1\n\n# afficher nb de components\nprint(n_components)", "execution_count": 53, "outputs": [{"output_type": "stream", "name": "stdout", "text": "262\n"}]}, {"metadata": {"id": "7kzlulEB7iO8"}, "id": "7kzlulEB7iO8", "cell_type": "markdown", "source": "Puis on applique de nouveau la pca avec le bon nombre de composante."}, {"metadata": {"id": "umcsrmEC6And", "trusted": false}, "id": "umcsrmEC6And", "cell_type": "code", "source": "pca = PCA(k=n_components, inputCol=\"features_vector\", outputCol=\"pca_features\")\npca_model = pca.fit(features_vector_df)\npca_features_df = pca_model.transform(features_vector_df).select(\"path\", \"label\", \"pca_features\")", "execution_count": 55, "outputs": []}, {"metadata": {"id": "eb5e83ec"}, "id": "eb5e83ec", "cell_type": "markdown", "source": "<u>Rappel du PATH o\u00f9 seront inscrits les fichiers au format \"**parquet**\" <br />\ncontenant nos r\u00e9sultats, \u00e0 savoir, un DataFrame contenant 3 colonnes</u> :\n 1. Path des images\n 2. Label de l'image\n 3. Vecteur de caract\u00e9ristiques de l'image"}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "67fcdb0f", "outputId": "7c5b687e-550e-4b63-a49d-d21eb6102f36", "trusted": false}, "id": "67fcdb0f", "cell_type": "code", "source": "print(PATH_Result)", "execution_count": 25, "outputs": [{"output_type": "stream", "name": "stdout", "text": "/content/drive/MyDrive/FORMATION DATASCIENTIST OC - Lucas GAMBA/Projet 9/data/Results\n"}]}, {"metadata": {"id": "f8901db3"}, "id": "f8901db3", "cell_type": "markdown", "source": "<u>Enregistrement des donn\u00e9es trait\u00e9es au format \"**parquet**\"</u> :"}, {"metadata": {"id": "95d07466", "trusted": false}, "id": "95d07466", "cell_type": "code", "source": "features_df.write.mode(\"overwrite\").parquet(PATH_Result)", "execution_count": 26, "outputs": []}, {"metadata": {"id": "2ActuDA20ehc", "trusted": false}, "id": "2ActuDA20ehc", "cell_type": "code", "source": "pca_features_df.write.mode(\"overwrite\").parquet(PATH_Result)", "execution_count": 56, "outputs": []}, {"metadata": {"id": "f9506f21"}, "id": "f9506f21", "cell_type": "markdown", "source": "## 3.8 Chargement des donn\u00e9es enregistr\u00e9es et validation du r\u00e9sultat\n\n<u>On charge les donn\u00e9es fraichement enregistr\u00e9es dans un **DataFrame Pandas**</u> :"}, {"metadata": {"id": "19243bf5", "trusted": false}, "id": "19243bf5", "cell_type": "code", "source": "df = pd.read_parquet(PATH_Result, engine='pyarrow')", "execution_count": 27, "outputs": []}, {"metadata": {"id": "27f15070"}, "id": "27f15070", "cell_type": "markdown", "source": "<u>On affiche les 5 premi\u00e8res lignes du DataFrame</u> :"}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 206}, "id": "_l81k4SN0vLj", "outputId": "46d06499-7a00-4eee-c82d-c9026928f364", "trusted": false}, "id": "_l81k4SN0vLj", "cell_type": "code", "source": "df.head()", "execution_count": 58, "outputs": [{"output_type": "execute_result", "data": {"text/plain": "                                                path         label  \\\n0  file:/content/drive/MyDrive/FORMATION DATASCIE...  Potato White   \n1  file:/content/drive/MyDrive/FORMATION DATASCIE...  Potato White   \n2  file:/content/drive/MyDrive/FORMATION DATASCIE...  Potato White   \n3  file:/content/drive/MyDrive/FORMATION DATASCIE...  Potato White   \n4  file:/content/drive/MyDrive/FORMATION DATASCIE...  Potato White   \n\n                                        pca_features  \n0  {'type': 1, 'size': None, 'indices': None, 'va...  \n1  {'type': 1, 'size': None, 'indices': None, 'va...  \n2  {'type': 1, 'size': None, 'indices': None, 'va...  \n3  {'type': 1, 'size': None, 'indices': None, 'va...  \n4  {'type': 1, 'size': None, 'indices': None, 'va...  ", "text/html": "\n  <div id=\"df-cf236ff5-595f-4ee4-99c4-bed6a05f69ea\" class=\"colab-df-container\">\n    <div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>path</th>\n      <th>label</th>\n      <th>pca_features</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>file:/content/drive/MyDrive/FORMATION DATASCIE...</td>\n      <td>Potato White</td>\n      <td>{'type': 1, 'size': None, 'indices': None, 'va...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>file:/content/drive/MyDrive/FORMATION DATASCIE...</td>\n      <td>Potato White</td>\n      <td>{'type': 1, 'size': None, 'indices': None, 'va...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>file:/content/drive/MyDrive/FORMATION DATASCIE...</td>\n      <td>Potato White</td>\n      <td>{'type': 1, 'size': None, 'indices': None, 'va...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>file:/content/drive/MyDrive/FORMATION DATASCIE...</td>\n      <td>Potato White</td>\n      <td>{'type': 1, 'size': None, 'indices': None, 'va...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>file:/content/drive/MyDrive/FORMATION DATASCIE...</td>\n      <td>Potato White</td>\n      <td>{'type': 1, 'size': None, 'indices': None, 'va...</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n    <div class=\"colab-df-buttons\">\n\n  <div class=\"colab-df-container\">\n    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cf236ff5-595f-4ee4-99c4-bed6a05f69ea')\"\n            title=\"Convert this dataframe to an interactive table.\"\n            style=\"display:none;\">\n\n  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n  </svg>\n    </button>\n\n  <style>\n    .colab-df-container {\n      display:flex;\n      gap: 12px;\n    }\n\n    .colab-df-convert {\n      background-color: #E8F0FE;\n      border: none;\n      border-radius: 50%;\n      cursor: pointer;\n      display: none;\n      fill: #1967D2;\n      height: 32px;\n      padding: 0 0 0 0;\n      width: 32px;\n    }\n\n    .colab-df-convert:hover {\n      background-color: #E2EBFA;\n      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n      fill: #174EA6;\n    }\n\n    .colab-df-buttons div {\n      margin-bottom: 4px;\n    }\n\n    [theme=dark] .colab-df-convert {\n      background-color: #3B4455;\n      fill: #D2E3FC;\n    }\n\n    [theme=dark] .colab-df-convert:hover {\n      background-color: #434B5C;\n      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n      fill: #FFFFFF;\n    }\n  </style>\n\n    <script>\n      const buttonEl =\n        document.querySelector('#df-cf236ff5-595f-4ee4-99c4-bed6a05f69ea button.colab-df-convert');\n      buttonEl.style.display =\n        google.colab.kernel.accessAllowed ? 'block' : 'none';\n\n      async function convertToInteractive(key) {\n        const element = document.querySelector('#df-cf236ff5-595f-4ee4-99c4-bed6a05f69ea');\n        const dataTable =\n          await google.colab.kernel.invokeFunction('convertToInteractive',\n                                                    [key], {});\n        if (!dataTable) return;\n\n        const docLinkHtml = 'Like what you see? Visit the ' +\n          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n          + ' to learn more about interactive tables.';\n        element.innerHTML = '';\n        dataTable['output_type'] = 'display_data';\n        await google.colab.output.renderOutput(dataTable, element);\n        const docLink = document.createElement('div');\n        docLink.innerHTML = docLinkHtml;\n        element.appendChild(docLink);\n      }\n    </script>\n  </div>\n\n\n<div id=\"df-6bed01cd-b60c-4627-990f-a39578da294a\">\n  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6bed01cd-b60c-4627-990f-a39578da294a')\"\n            title=\"Suggest charts\"\n            style=\"display:none;\">\n\n<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n     width=\"24px\">\n    <g>\n        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n    </g>\n</svg>\n  </button>\n\n<style>\n  .colab-df-quickchart {\n      --bg-color: #E8F0FE;\n      --fill-color: #1967D2;\n      --hover-bg-color: #E2EBFA;\n      --hover-fill-color: #174EA6;\n      --disabled-fill-color: #AAA;\n      --disabled-bg-color: #DDD;\n  }\n\n  [theme=dark] .colab-df-quickchart {\n      --bg-color: #3B4455;\n      --fill-color: #D2E3FC;\n      --hover-bg-color: #434B5C;\n      --hover-fill-color: #FFFFFF;\n      --disabled-bg-color: #3B4455;\n      --disabled-fill-color: #666;\n  }\n\n  .colab-df-quickchart {\n    background-color: var(--bg-color);\n    border: none;\n    border-radius: 50%;\n    cursor: pointer;\n    display: none;\n    fill: var(--fill-color);\n    height: 32px;\n    padding: 0;\n    width: 32px;\n  }\n\n  .colab-df-quickchart:hover {\n    background-color: var(--hover-bg-color);\n    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n    fill: var(--button-hover-fill-color);\n  }\n\n  .colab-df-quickchart-complete:disabled,\n  .colab-df-quickchart-complete:disabled:hover {\n    background-color: var(--disabled-bg-color);\n    fill: var(--disabled-fill-color);\n    box-shadow: none;\n  }\n\n  .colab-df-spinner {\n    border: 2px solid var(--fill-color);\n    border-color: transparent;\n    border-bottom-color: var(--fill-color);\n    animation:\n      spin 1s steps(1) infinite;\n  }\n\n  @keyframes spin {\n    0% {\n      border-color: transparent;\n      border-bottom-color: var(--fill-color);\n      border-left-color: var(--fill-color);\n    }\n    20% {\n      border-color: transparent;\n      border-left-color: var(--fill-color);\n      border-top-color: var(--fill-color);\n    }\n    30% {\n      border-color: transparent;\n      border-left-color: var(--fill-color);\n      border-top-color: var(--fill-color);\n      border-right-color: var(--fill-color);\n    }\n    40% {\n      border-color: transparent;\n      border-right-color: var(--fill-color);\n      border-top-color: var(--fill-color);\n    }\n    60% {\n      border-color: transparent;\n      border-right-color: var(--fill-color);\n    }\n    80% {\n      border-color: transparent;\n      border-right-color: var(--fill-color);\n      border-bottom-color: var(--fill-color);\n    }\n    90% {\n      border-color: transparent;\n      border-bottom-color: var(--fill-color);\n    }\n  }\n</style>\n\n  <script>\n    async function quickchart(key) {\n      const quickchartButtonEl =\n        document.querySelector('#' + key + ' button');\n      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n      quickchartButtonEl.classList.add('colab-df-spinner');\n      try {\n        const charts = await google.colab.kernel.invokeFunction(\n            'suggestCharts', [key], {});\n      } catch (error) {\n        console.error('Error during call to suggestCharts:', error);\n      }\n      quickchartButtonEl.classList.remove('colab-df-spinner');\n      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n    }\n    (() => {\n      let quickchartButtonEl =\n        document.querySelector('#df-6bed01cd-b60c-4627-990f-a39578da294a button');\n      quickchartButtonEl.style.display =\n        google.colab.kernel.accessAllowed ? 'block' : 'none';\n    })();\n  </script>\n</div>\n\n    </div>\n  </div>\n", "application/vnd.google.colaboratory.intrinsic+json": {"type": "dataframe", "variable_name": "df2", "summary": "{\n  \"name\": \"df2\",\n  \"rows\": 314,\n  \"fields\": [\n    {\n      \"column\": \"path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 314,\n        \"samples\": [\n          \"file:/content/drive/MyDrive/FORMATION DATASCIENTIST OC - Lucas GAMBA/Projet 9/data/Test1/Potato White/r_34_100.jpg\",\n          \"file:/content/drive/MyDrive/FORMATION DATASCIENTIST OC - Lucas GAMBA/Projet 9/data/Test1/Potato White/r_144_100.jpg\",\n          \"file:/content/drive/MyDrive/FORMATION DATASCIENTIST OC - Lucas GAMBA/Projet 9/data/Test1/Redcurrant/r_129_100.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Redcurrant\",\n          \"Potato White\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pca_features\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}}, "metadata": {}, "execution_count": 58}]}, {"metadata": {"id": "e2794fca"}, "id": "e2794fca", "cell_type": "markdown", "source": "<u>On valide que la dimension du vecteur de caract\u00e9ristiques des images est bien de dimension 1280</u> :"}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "pZ5-wcO_3JRh", "outputId": "059c028a-54d6-4c10-81c0-b60b06be1d04", "trusted": false}, "id": "pZ5-wcO_3JRh", "cell_type": "code", "source": "df2.pca_features[0]['values'].shape", "execution_count": 59, "outputs": [{"output_type": "execute_result", "data": {"text/plain": "(262,)"}, "metadata": {}, "execution_count": 59}]}, {"metadata": {"id": "efe5348d"}, "id": "efe5348d", "cell_type": "markdown", "source": "Nous venons de valider le processus sur un jeu de donn\u00e9es all\u00e9g\u00e9 en local <br />\no\u00f9 nous avons simul\u00e9 un cluster de machines en r\u00e9partissant la charge de travail <br />\nsur diff\u00e9rents c\u0153urs de processeur au sein d'une m\u00eame machine.\n\nNous allons maintenant g\u00e9n\u00e9raliser le processus en d\u00e9ployant notre solution <br />\nsur un r\u00e9el cluster de machines et nous travaillerons d\u00e9sormais sur la totalit\u00e9 <br />\ndes 22819 images de notre dossier \"Test\"."}, {"metadata": {"id": "a0f0f7c1"}, "id": "a0f0f7c1", "cell_type": "markdown", "source": "# 4. D\u00e9ploiement de la solution sur le cloud\n\nMaintenant que nous avons v\u00e9rifi\u00e9 que notre solution fonctionne, <br />\nil est temps de la <u>d\u00e9ployer \u00e0 plus grande \u00e9chelle sur un vrai cluster de machines</u>.\n\n**Attention**, *je travaille sous Linux avec une version Ubuntu, <br />\nles commandes d\u00e9crites ci-dessous sont donc r\u00e9alis\u00e9es <br />\nexclusivement dans cet environnement.*\n\n<u>Plusieurs contraintes se posent</u> :\n 1. Quel prestataire de Cloud choisir ?\n 2. Quelles solutions de ce prestataire adopter ?\n 3. O\u00f9 stocker nos donn\u00e9es ?\n 4. Comment configurer nos outils dans ce nouvel environnement ?\n\n## 4.1 Choix du prestataire cloud : AWS\n\nLe prestataire le plus connu et qui offre \u00e0 ce jour l'offre <br />\nla plus large dans le cloud computing est **Amazon Web Services** (AWS).<br />\nCertaines de leurs offres sont parfaitement adapt\u00e9es \u00e0 notre probl\u00e9matique <br />\net c'est la raison pour laquelle j'utiliserai leurs services.\n\nL'objectif premier est de pouvoir, gr\u00e2ce \u00e0 AWS, <u>louer de la puissance de calcul \u00e0 la demande</u>. <br />\nL'id\u00e9e \u00e9tant de pouvoir, quel que soit la charge de travail, <br />\nobtenir suffisamment de puissance de calcul pour pouvoir traiter nos images, <br />\nm\u00eame si le volume de donn\u00e9es venait \u00e0 fortement augmenter.\n\nDe plus, la capacit\u00e9 d'utiliser cette puissance de calcul \u00e0 la demande <br />\npermet de diminuer drastiquement les co\u00fbts si l'on compare les co\u00fbts d'une location <br />\nde serveur complet sur une dur\u00e9e fixe (1 mois, 1 ann\u00e9e par exemple).\n\n## 4.2 Choix de la solution technique : EMR\n\n<u>Plusieurs solutions s'offre \u00e0 nous</u> :\n1. Solution **IAAS** (Infrastructure AS A Service)\n - Dans cette configuration **AWS** met \u00e0 notre disposition des serveurs vierges <br />\n   sur lequel nous avons un acc\u00e8s en administrateur, ils sont nomm\u00e9s **instance EC2**.<br />\n   Pour faire simple, nous pouvons avec cette solution reproduire pratiquement <br />\n   \u00e0 l'identique la solution mis en \u0153uvre en local sur notre machine.<br />\n   <u>On installe nous-m\u00eame l'int\u00e9gralit\u00e9 des outils puis on ex\u00e9cute notre script</u> :\n  - Installation de **Spark**, **Java** etc.\n  - Installation de **Python** (via Anaconda par exemple)\n  - Installation de **Jupyter Notebook**\n  - Installation des **librairies compl\u00e9mentaires**\n  - Il faudra bien \u00e9videment veiller \u00e0 **impl\u00e9menter les librairies\n    n\u00e9cessaires \u00e0 toutes les machines (workers) du cluster**\n  - <u>Avantages</u> :\n      - Libert\u00e9 totale de mise en \u0153uvre de la solution\n      - Facilit\u00e9 de mise en \u0153uvre \u00e0 partir d'un mod\u00e8le qui s'ex\u00e9cute en local sur une machine Linux\n  - <u>Inconv\u00e9nients</u> :\n      - Cronophage\n          - N\u00e9cessit\u00e9 d'installer et de configurer toute la solution\n      - Possible probl\u00e8mes techniques \u00e0 l'installation des outils (des probl\u00e9matiques qui <br />\n        n'existaient pas en local sur notre machine peuvent apparaitre sur le serveur EC2)\n      - Solution non p\u00e9renne dans le temps, il faudra veiller \u00e0 la mise \u00e0 jour des outils <br />\n        et \u00e9ventuellement devoir r\u00e9installer Spark, Java etc.\n2. Solution **PAAS** (Plateforme As A Service)\n - **AWS** fournit \u00e9norm\u00e9ment de services diff\u00e9rents, dans l'un de ceux-l\u00e0 <br />\n   il existe une offre qui permet de louer des **instances EC2** <br />\n   avec des applications pr\u00e9install\u00e9es et configur\u00e9es : il s'agit du **service EMR**.\n - **Spark** y sera d\u00e9j\u00e0 install\u00e9\n - Possibilit\u00e9 de demander l'installation de **Tensorflow** ainsi que **JupyterHub**\n - Possibilit\u00e9 d'indiquer des **packages compl\u00e9mentaires** \u00e0 installer <br />\n   \u00e0 l'initialisation du serveur **sur l'ensemble des machines du cluster**.\n - <u>Avantages</u> :\n     - Facilit\u00e9 de mise en \u0153uvre\n         - Il suffit de tr\u00e8s peu de configuration pour obtenir <br />\n           un environnement parfaitement fonctionnel\n     - Rapidit\u00e9 de mise en \u0153uvre\n         - Une fois la premi\u00e8re configuration r\u00e9alis\u00e9e, il est tr\u00e8s facile <br />\n           et tr\u00e8s rapide de recr\u00e9er des clusters \u00e0 l'identique qui seront <br />\n           disponibles presque instantan\u00e9ment (le temps d'instancier les <br />\n           serveurs soit environ 15/20 minutes)\n     - Solutions mat\u00e9rielless et logicielles optimis\u00e9es par les ing\u00e9nieurs d'AWS\n         - On sait que les versions install\u00e9es vont fonctionner <br />\n           et que l'architecture propos\u00e9e est optimis\u00e9e\n     - Stabilit\u00e9 de la solution\n    - Solution \u00e9volutive\n        Il est facile d\u2019obtenir \u00e0 chaque nouvelle instanciation une version \u00e0 jour <br />\n        de chaque package, en \u00e9tant garanti de leur compatibilit\u00e9 avec le reste de l\u2019environnement.\n  - Plus s\u00e9curis\u00e9\n\t- Les \u00e9ventuels patchs de s\u00e9curit\u00e9 seront automatiquement mis \u00e0 jour <br />\n      \u00e0 chaque nouvelle instanciation du cluster EMR.\n - <u>Inconv\u00e9nients</u> :\n     - Peut-\u00eatre un certain manque de libert\u00e9 sur la version des packages disponibles ? <br />\n       M\u00eame si je n'ai pas constat\u00e9 ce probl\u00e8me.\n   \n\nJe retiens la solution **PAAS** en choisissant d'utiliser <br />\nle service **EMR** d'Amazon Web Services.<br />\nJe la trouve plus adapt\u00e9e \u00e0 notre probl\u00e9matique et permet <br />\nune mise en \u0153uvre qui soit \u00e0 la fois plus rapide et <br />\nplus efficace que la solution IAAS.\n\n## 4.3 Choix de la solution de stockage des donn\u00e9es : Amazon S3\n\n<u>Amazon propose une solution tr\u00e8s efficace pour la gestion du stockage des donn\u00e9es</u> : **Amazon S3**. <br />\nS3 pour Amazon Simple Storage Service.\n\nIl pourrait \u00eatre tentant de stocker nos donn\u00e9es sur l'espace allou\u00e9 par le serveur **EC2**, <br />\nmais si nous ne prenons aucune mesure pour les sauvegarder ensuite sur un autre support, <br />\n<u>les donn\u00e9es seront perdues</u> lorsque le serveur sera r\u00e9sili\u00e9 (on r\u00e9silie le serveur lorsqu'on <br />\nne s'en sert pas pour des raisons de co\u00fbt).<br />\nDe fait, si l'on d\u00e9cide d'utiliser l'espace disque du serveur EC2 il faudra imaginer <br />\nune solution pour sauvegarder les donn\u00e9es avant la r\u00e9siliation du serveur.\nDe plus, nous serions expos\u00e9s \u00e0 certaines probl\u00e9matiques si nos donn\u00e9es venaient \u00e0 <br />\n**saturer** l'espace disponible de nos serveurs (ralentissements, disfonctionnements).\n\n<u>Utiliser **Amazon S3** permet de s'affranchir de toutes ces probl\u00e9matiques</u>. <br />\nL'espace disque disponible est **illimit\u00e9**, et il est **ind\u00e9pendant de nos serveurs EC2**. <br />\nL'acc\u00e8s aux donn\u00e9es est **tr\u00e8s rapide** car nous restons dans l'environnement d'AWS <br />\net nous prenons soin de <u>choisir la m\u00eame r\u00e9gion pour nos serveurs **EC2** et **S3**</u>.\n\nDe plus, comme nous le verrons <u>il est possible d'acc\u00e9der aux donn\u00e9es sur **S3** <br />\n    de la m\u00eame mani\u00e8re que l'on **acc\u00e8de aux donn\u00e9es sur un disque local**</u>.<br />\nNous utiliserons simplement un **PATH au format s3://...** .\n\n## 4.4 Configuration de l'environnement de travail\n\nLa premi\u00e8re \u00e9tape est d'installer et de configurer [**AWS Cli**](https://aws.amazon.com/fr/cli/),<br />\nil s'agit de l'**interface en ligne de commande d'AWS**.<br />\nElle nous permet d'**interagir avec les diff\u00e9rents services d'AWS**, comme **S3** par exemple.\n\nPour pouvoir utiliser **AWS Cli**, il faut le configurer en cr\u00e9ant pr\u00e9alablement <br />\nun utilisateur \u00e0 qui on donnera les autorisations dont nous aurons besoin.<br />\nDans ce projet il faut que l'utilisateur ait \u00e0 minima un contr\u00f4le total sur le service S3.\n\n<u>La gestion des utilisateurs et de leurs droits s'effectue via le service **AMI**</u> d'AWS.\n\nUne fois l'utilisateur cr\u00e9\u00e9 et ses autorisations configur\u00e9es nous cr\u00e9ons une **paire de cl\u00e9s** <br />\nqui nous permettra de nous **connecter sans \u00e0 avoir \u00e0 devoir saisir syst\u00e9matiquement notre login/mot de passe**.<br />\n\nIl faut \u00e9galement configurer l'**acc\u00e8s SSH** \u00e0 nos futurs serveurs EC2. <br />\nIci aussi, via un syst\u00e8me de cl\u00e9s qui nous dispense de devoir nous authentifier \"\u00e0 la main\" \u00e0 chaque connexion.\n\nToutes ses \u00e9tapes de configuration sont parfaitement d\u00e9crites <br />\ndans le cours du projet: [R\u00e9alisez des calculs distribu\u00e9s sur des donn\u00e9es massives / D\u00e9couvrez Amazon Web Services](https://openclassrooms.com/fr/courses/4297166-realisez-des-calculs-distribues-sur-des-donnees-massives/4308686-decouvrez-amazon-web-services#/id/r-4355822)\n\n## 4.5 Upload de nos donn\u00e9es sur S3\n\nNos outils sont configur\u00e9s. <br />\nIl faut maintenant uploader nos donn\u00e9es de travail sur Amazon S3.\n\nIci aussi les \u00e9tapes sont d\u00e9crites avec pr\u00e9cision <br />\ndans le cours [R\u00e9alisez des calculs distribu\u00e9s sur des donn\u00e9es massives / Stockez des donn\u00e9es sur S3](https://openclassrooms.com/fr/courses/4297166-realisez-des-calculs-distribues-sur-des-donnees-massives/4308691-stockez-des-donnees-sur-s3)\n\nJe d\u00e9cide de n'uploader que les donn\u00e9es contenues dans le dossier **Test** du [jeu de donn\u00e9es du projet](https://www.kaggle.com/moltean/fruits/download)\n\n\nLa premi\u00e8re \u00e9tape consiste \u00e0 **cr\u00e9er un bucket sur S3** <br />\ndans lequel nous uploaderons les donn\u00e9es du projet:\n- **aws s3 mb s3://p8-data**\n\nOn v\u00e9rifie que le bucket \u00e0 bien \u00e9t\u00e9 cr\u00e9\u00e9\n- **aws s3 ls**\n - Si le nom du bucket s'affiche alors c'est qu'il a \u00e9t\u00e9 correctement cr\u00e9\u00e9.\n\nOn copie ensuite le contenu du dossier \"**Test**\" <br />\ndans un r\u00e9pertoire \"**Test**\" sur notre bucket \"**p8-data**\":\n1. On se place \u00e0 l'int\u00e9rieur du r\u00e9pertoire **Test**\n2. **aws sync . s3://p8-data/Test**\n\nLa commande **sync** est utile pour synchroniser deux r\u00e9pertoires.\n\n<u>Nos donn\u00e9es du projet sont maintenant disponibles sur Amazon S3</u>.\n\n## 4.6 Configuration du serveur EMR\n\nUne fois encore, le cours [R\u00e9alisez des calculs distribu\u00e9s sur des donn\u00e9es massives / D\u00e9ployez un cluster de calculs distribu\u00e9s](https://openclassrooms.com/fr/courses/4297166-realisez-des-calculs-distribues-sur-des-donnees-massives/4308696-deployez-un-cluster-de-calculs-distribues) <br /> d\u00e9taille l'essentiel des \u00e9tapes pour lancer un cluster avec **EMR**.\n\n<u>Je d\u00e9taillerai ici les \u00e9tapes particuli\u00e8res qui nous permettent <br />\nde configurer le serveur selon nos besoins</u> :\n\n1. Cliquez sur Cr\u00e9er un cluster\n![Cr\u00e9er un cluster](img/EMR_creer.png)\n2. Cliquez sur Acc\u00e9der aux options avanc\u00e9es\n![Cr\u00e9er un cluster](img/EMR_options_avancees.png)\n\n### 4.6.1 \u00c9tape 1 : Logiciels et \u00e9tapes\n\n#### 4.6.1.1 Configuration des logiciels\n\n<u>S\u00e9lectionnez les packages dont nous aurons besoin comme dans la capture d'\u00e9cran</u> :\n1. Nous s\u00e9lectionnons la derni\u00e8re version d'**EMR**, soit la version **6.3.0** au moment o\u00f9 je r\u00e9dige ce document\n2. Nous cochons bien \u00e9videment **Hadoop** et **Spark** qui seront pr\u00e9install\u00e9s dans leur version la plus r\u00e9cente\n3. Nous aurons \u00e9galement besoin de **TensorFlow** pour importer notre mod\u00e8le et r\u00e9aliser le **transfert learning**\n4. Nous travaillerons enfin avec un **notebook Jupyter** via l'application **JupyterHub**<br />\n - Comme nous le verrons dans un instant nous allons <u>param\u00e9trer l'application afin que les notebooks</u>, <br />\n   comme le reste de nos donn\u00e9es de travail, <u>soient enregistr\u00e9s directement sur S3</u>.\n![Cr\u00e9er un cluster](img/EMR_configuration_logiciels.png)\n\n#### 4.6.1.2 Modifier les param\u00e8tres du logiciel\n\n<u>Param\u00e9trez la persistance des notebooks cr\u00e9\u00e9s et ouvert via JupyterHub</u> :\n- On peut \u00e0 cette \u00e9tape effectuer des demandes de param\u00e9trage particuli\u00e8res sur nos applications. <br />\n  L'objectif est, comme pour le reste de nos donn\u00e9es de travail, <br />\n  d'\u00e9viter toutes les probl\u00e9matiques \u00e9voqu\u00e9es pr\u00e9c\u00e9demment. <br />\n  C'est l'objectif \u00e0 cette \u00e9tape, <u>nous allons enregistrer <br />\n  et ouvrir les notebooks</u> non pas sur l'espace disque de  l'instance EC2 (comme <br />\n  ce serait le cas dans la configuration par d\u00e9faut de JupyterHub) mais <br />\n  <u>directement sur **Amazon S3**</u>.\n- <u>deux solutions sont possibles pour r\u00e9aliser cela</u> :\n 1. Cr\u00e9er un **fichier de configuration JSON** que l'on **upload sur S3** et on indique ensuite le chemin d\u2019acc\u00e8s au fichier JSON\n 2. Rentrez directement la configuration au format JSON\n\nJ'ai personnellement cr\u00e9\u00e9 un fichier JSON lors de la cr\u00e9ation de ma premi\u00e8re instance EMR, <br />\npuis lorsqu'on d\u00e9cide de cloner notre serveur pour en recr\u00e9er un facilement \u00e0 l'identique, <br />\nla configuration du fichier JSON se retrouve directement copi\u00e9 comme dans la capture ci-dessous.\n\n<u>Voici le contenu de mon fichier JSON</u> :  [{\"classification\":\"jupyter-s3-conf\",\"properties\":{\"s3.persistence.bucket\":\"p8-data\",\"s3.persistence.enabled\":\"true\"}}]\n Appuyez ensuite sur \"**Suivant**\"\n![Modifier les param\u00e8tres du logiciel](img/EMR_parametres_logiciel.png)\n\n### 4.6.2 \u00c9tape 2 : Mat\u00e9riel\n\nA cette \u00e9tape, laissez les choix par d\u00e9faut. <br />\n<u>L'important ici est la s\u00e9lection de nos instances</u> :\n\n1. je choisi les instances de type **M5** qui sont des **instances de type \u00e9quilibr\u00e9s**\n2. je choisi le type **xlarge** qui est l'instance la **moins on\u00e9reuse disponible**\n [Plus d'informations sur les instances M5 Amazon EC2](https://aws.amazon.com/fr/ec2/instance-types/m5/)\n3. Je s\u00e9lectionne **1 instance Ma\u00eetre** (le driver) et **2 instances Principales** (les workeurs) <br />\n   soit **un total de 3 instance EC2**.\n![Choix du materiel](img/EMR_materiel.png)\n\n### 4.6.3 \u00c9tape 3 : Param\u00e8tres de cluster g\u00e9n\u00e9raux\n\n#### 4.6.3.1 Options g\u00e9n\u00e9rales\n<u>La premi\u00e8re chose \u00e0 faire est de donner un nom au cluster</u> :<br />\n*J'ai \u00e9galement d\u00e9coch\u00e9 \"Protection de la r\u00e9siliation\" pour des raisons pratiques.*\n    \n![Nom du Cluster](img/EMR_nom_cluster.png)\n\n#### 4.6.3.2 Actions d'amor\u00e7age\n\nNous allons \u00e0 cette \u00e9tape **choisir les packages manquants \u00e0 installer** et qui <br />\nnous serons utiles dans l'ex\u00e9cution de notre notebook.<br />\n<u>L'avantage de r\u00e9aliser cette \u00e9tape maintenant est que les packages <br />\ninstall\u00e9s le seront sur l'ensemble des machines du cluster</u>.\n\nLa proc\u00e9dure pour cr\u00e9er le fichier **bootstrap** qui contient <br />\nl'ensemble des instructions permettant d'installer tous <br />\nles packages dont nous aurons besoin est expliqu\u00e9 dans <br />\nle cours [R\u00e9alisez des calculs distribu\u00e9s sur des donn\u00e9es massives / Bootstrapping](https://openclassrooms.com/fr/courses/4297166-realisez-des-calculs-distribues-sur-des-donnees-massives/4308696-deployez-un-cluster-de-calculs-distribues#/id/r-4356490)\n\nNous cr\u00e9ons donc un fichier nomm\u00e9 \"**bootstrap-emr.sh**\" que nous <u>uploadons <br />\nsur S3</u>(je l\u2019installe \u00e0 la racine de mon **bucket \"p8-data\"**) et nous l'ajoutons <br />\ncomme indiqu\u00e9 dans la capture d'\u00e9cran ci-dessous:\n![Actions d'amorcage](img/EMR_amorcage.png)\n\nVoici le contenu du fichier **bootstrap-emr.sh**<br />\nComme on peut le constater il s'agit simplement de commande \"**pip install**\" <br />\npour **installer les biblioth\u00e8ques manquantes** comme r\u00e9alis\u00e9 en local.<br />\nUne fois encore, <u>il est n\u00e9cessaire de r\u00e9aliser ces actions \u00e0 cette \u00e9tape</u> <br />\npour que <u>les packages soient install\u00e9s sur l'ensemble des machines du cluster</u> <br />\net non pas uniquement sur le driver, comme cela serait le cas si nous ex\u00e9cutions <br />\nces commandes directement dans le notebook JupyterHub ou dans la console EMR (connect\u00e9 au driver).\n![Contenu du fichier bootstrap](img/EMR_bootstrap.png)\n\n**setuptools** et **pip** sont mis \u00e0 jour pour \u00e9viter une probl\u00e9matique <br />\navec l'installation du package **pyarrow**.<br />\n**Pandas** a eu droit \u00e0 une mise \u00e0 jour majeur (1.3.0) il y a moins d'une semaine <br />\nau moment de la r\u00e9daction de ce notebook, et la nouvelle version de **Pandas** <br />\nn\u00e9cessite une version plus r\u00e9cente de **Numpy** que la version install\u00e9e par <br />\nd\u00e9faut (1.16.5) \u00e0 l'initialisation des instances **EC2**. <u>Il ne semble pas <br />\npossible d'imposer une autre version de Numpy que celle install\u00e9 par <br />\nd\u00e9faut</u> m\u00eame si on force l'installation d'une version r\u00e9cente de **Numpy** <br />\n(en tout cas, ni simplement ni intuitivement).<br />\nLa mise \u00e0 jour \u00e9tant tr\u00e8s r\u00e9cente <u>la version de **Numpy** n'est pas encore <br />\nmise \u00e0 jour sur **EC2**</u> mais on peut imaginer que ce sera le cas tr\u00e8s rapidement <br />\net il ne sera plus n\u00e9cessaire d'imposer une version sp\u00e9cifique de **Pandas**.<br />\nEn attendant, je demande <u>l'installation de l'avant derni\u00e8re version de **Pandas (1.2.5)**</u>\n\nOn clique ensuite sur ***Suivant***\n\n### 4.6.4 \u00c9tape 4 : S\u00e9curit\u00e9\n\n#### 4.6.4.1 Options de s\u00e9curit\u00e9\n\nA cette \u00e9tape nous s\u00e9lectionnons la **paire de cl\u00e9s EC2** cr\u00e9\u00e9 pr\u00e9c\u00e9demment. <br />\nElle nous permettra de se connecter en **ssh** \u00e0 nos **instances EC2** <br />\nsans avoir \u00e0 entrer nos login/mot de passe.<br />\nOn laisse les autres param\u00e8tres par d\u00e9faut. <br />\nEt enfin, on clique sur \"***Cr\u00e9er un cluster***\"\n\n![EMR S\u00e9curit\u00e9](img/EMR_securite.png)\n\n## 4.7 Instanciation du serveur\n\nIl ne nous reste plus qu'\u00e0 attendre que le serveur soit pr\u00eat. <br />\nCette \u00e9tape peut prendre entre **15 et 20 minutes**.\n\n<u>Plusieurs \u00e9tapes s'encha\u00eene, on peut suivre l'avanc\u00e9 du statut du **cluster EMR**</u> :\n\n![Instanciation \u00e9tape 1](img/EMR_instanciation_01.png)\n![Instanciation \u00e9tape 2](img/EMR_instanciation_02.png)\n![Instanciation \u00e9tape 3](img/EMR_instanciation_03.png)\n\n<u>Lorsque le statut affiche en vert: \"**En attente**\" cela signifie que l'instanciation <br />\ns'est bien d\u00e9roul\u00e9e et que notre serveur est pr\u00eat \u00e0 \u00eatre utilis\u00e9</u>.\n\n## 4.8 Cr\u00e9ation du tunnel SSH \u00e0 l'instance EC2 (Ma\u00eetre)\n\n### 4.8.1 Cr\u00e9ation des autorisations sur les connexions entrantes\n\n<u>Nous souhaitons maintenant pouvoir acc\u00e9der \u00e0 nos applications</u> :\n - **JupyterHub** pour l'ex\u00e9cution de notre notebook\n - **Serveur d'historique Spark** pour le suivi de l'ex\u00e9cution <br />\n   des t\u00e2ches de notre script lorsqu'il sera lanc\u00e9\n\nCependant, <u>ces applications ne sont accessibles que depuis le r\u00e9seau local du driver</u>, <br />\net pour y acc\u00e9der nous devons **cr\u00e9er un tunnel SSH vers le driver**.\n\nPar d\u00e9faut, ce driver se situe derri\u00e8re un firewall qui bloque l'acc\u00e8s en SSH. <br />\n<u>Pour ouvrir le port 22 qui correspond au port sur lequel \u00e9coute le serveur SSH, <br />\nil faut modifier le **groupe de s\u00e9curit\u00e9 EC2 du driver**</u>.\n\nCette \u00e9tape est d\u00e9crite dans le cours [R\u00e9alisez des calculs distribu\u00e9s sur des donn\u00e9es massives / Lancement d'une application \u00e0 partir du driver](https://openclassrooms.com/fr/courses/4297166-realisez-des-calculs-distribues-sur-des-donnees-massives/4308696-deployez-un-cluster-de-calculs-distribues#/id/r-4356512):\n\n*Il faudra que l'on se connecte en SSH au driver de notre cluster. <br />\nPar d\u00e9faut, ce driver se situe derri\u00e8re un firewall qui bloque l'acc\u00e8s en SSH. <br />\nPour ouvrir le port 22 qui correspond au port sur lequel \u00e9coute le serveur SSH, <br />\nil faut modifier le groupe de s\u00e9curit\u00e9 EC2 du driver. Sur la page de la console <br />\nconsacr\u00e9e \u00e0 EC2, dans l'onglet \"R\u00e9seau et s\u00e9curit\u00e9\", cliquez sur \"Groupes de s\u00e9curit\u00e9\". <br />\nVous allez devoir modifier le groupe de s\u00e9curit\u00e9 d\u2019ElasticMapReduce-Master. <br />\nDans l'onglet \"Entrant\", ajoutez une r\u00e8gle SSH dont la source est \"N'importe o\u00f9\" <br />\n(ou \"Mon IP\" si vous disposez d'une adresse IP fixe).*\n\n![Configuration autorisation ports entrants pour ssh](img/EMR_config_ssh_01.png)\n\n<u>Une fois cette \u00e9tape r\u00e9alis\u00e9e vous devriez avoir une configuration semblable \u00e0 la mienne</u> :\n\n![Configuration ssh termin\u00e9e](img/EMR_config_ssh_02.png)\n\n### 4.8.2 Cr\u00e9ation du tunnel ssh vers le Driver\n\nOn peut maintenant \u00e9tablir le **tunnel SSH** vers le **Driver**. <br />\nPour cela on r\u00e9cup\u00e8re les informations de connexion fournis par Amazon <br />\ndepuis la page du service EMR / Cluster / onglet R\u00e9capitulatif en <br />\ncliquant sur \"**Activer la connexion Web**\"\n\n![Activer la connexion Web](img/EMR_tunnel_ssh_01.png)\n\n<u>On r\u00e9cup\u00e8re ensuite la commande fournis par Amazon pour **\u00e9tablir le tunnel SSH**</u> :\n\n![R\u00e9cup\u00e9rer la commande pour \u00e9tablir le tunnel ssh](img/EMR_tunnel_ssh_02.png)\n\n<u>Dans mon cas, la commande ne fonctionne pas tel</u> quel et j'ai du **l'adapter \u00e0 ma configuration**. <br />\nLa **cl\u00e9 ssh** se situe dans un dossier \"**.ssh**\" elle-m\u00eame situ\u00e9e dans <br />\nmon **r\u00e9pertoire personnel** dont le symbole est, sous Linux, identifi\u00e9 par un tilde \"**~**\".\n\nAyant suivi le cours [R\u00e9alisez des calculs distribu\u00e9s sur des donn\u00e9es massives / Lancement d'une application \u00e0 partir du driver](https://openclassrooms.com/fr/courses/4297166-realisez-des-calculs-distribues-sur-des-donnees-massives) <br />\nj'ai choisi d'utiliser le port **5555** au lieu du **8157**, m\u00eame si le choix n'est pas tr\u00e8s important.<br />\n    j'ai \u00e9galement rencontr\u00e9 un <u>probl\u00e8me de compatibilit\u00e9</u> avec <br />\nl'argument \"**-N**\" (liste des arguments et leur significations <br />\ndisponibles [ici](https://explainshell.com/explain?cmd=ssh+-L+-N+-f+-l+-D)) j'ai d\u00e9cid\u00e9 de simplement le supprimer.\n\n<u>Finalement, j'utilise la commande suivante dans un terminal pour \u00e9tablir <br />\n    mon tunnel ssh (seul l'URL change d'une instance \u00e0 une autre)</u> : <br />\n\"**ssh -i ~/.ssh/p8-ec2.pem -D 5555 hadoop@ec2-35-180-91-39.eu-west-3.compute.amazonaws.com**\"\n\n<u>On inscrit \"**yes**\" pour valider la connexion et si <br />\n    la connexion est \u00e9tablit on obtient le r\u00e9sultat suivant</u> :\n\n![Cr\u00e9ation du tunnel SSH](img/EMR_connexion_ssh_01.png)\n\nNous avons **correctement \u00e9tabli le tunnel ssh avec le driver** sur le port \"5555\".\n\n### 4.8.3 Configuration de FoxyProxy\n\nUne derni\u00e8re \u00e9tape est n\u00e9cessaire pour acc\u00e9der \u00e0 nos applications, <br />\nen demandant \u00e0 notre navigateur d'emprunter le tunnel ssh.<br />\nJ'utilise pour cela **FoxyProxy**.\n[Une fois encore, vous pouvez utiliser le cours pour le configurer](https://openclassrooms.com/fr/courses/4297166-realisez-des-calculs-distribues-sur-des-donnees-massives/4308701-realisez-la-maintenance-dun-cluster#/id/r-4356554).\n\nSinon, ouvrez la configuration de **FoxyProxy** et <u>cliquez sur **Ajouter**</u> en haut \u00e0 gauche <br />\npuis renseigner les \u00e9l\u00e9ments comme dans la capture ci-dessous :\n\n![Configuration FoxyProxy Etape 1](img/EMR_foxyproxy_config_01.png)\n\n<u>On obtient le r\u00e9sultat ci-dessous</u> :\n\n![Configuration FoxyProxy Etape 2](img/EMR_foxyproxy_config_02.png)\n\n\n### 4.8.4 Acc\u00e8s aux applications du serveur EMR via le tunnel ssh\n\n\n<u>Avant d'\u00e9tablir notre **tunnel ssh** nous avions \u00e7a</u> :\n\n![avant tunnel ssh](img/EMR_tunnel_ssh_avant.png)\n\n<u>On active le **tunnel ssh** comme vu pr\u00e9c\u00e9demment puis on demande <br />\n\u00e0 notre navigateur de l'utiliser avec **FoxyProxy**</u> :\n\n![FoxyProxy activation](img/EMR_foxyproxy_activation.png)\n\n<u>On peut maintenant s'apercevoir que plusieurs applications nous sont accessibles</u> :\n\n![avant tunnel ssh](img/EMR_tunnel_ssh_apres.png)\n\n## 4.9 Connexion au notebook JupyterHub\n\nPour se connecter \u00e0 **JupyterHub** en vue d'ex\u00e9cuter notre **notebook**, <br />\nil faut commencer par <u>cliquer sur l'application **JupyterHub**</u> apparu <br />\ndepuis que nous avons configur\u00e9 le **tunnel ssh** et **foxyproxy** sur <br />\nnotre navigateur (actualisez la page si ce n\u2019est pas le cas).\n\n![D\u00e9marrage de JupyterHub](img/EMR_jupyterhub_connexion_01.png)\n\nOn passe les \u00e9ventuels avertissements de s\u00e9curit\u00e9 puis <br />\nnous arrivons sur une page de connexion.\n    \n<u>On se connecte avec les informations par d\u00e9faut</u> :\n - <u>login</u>: **jovyan**\n - <u>password</u>: **jupyter**\n\n![Connexion \u00e0 JupyterHub](img/EMR_jupyterhub_connexion_02.png)\n\nNous arrivons ensuite dans un dossier vierge de notebook.<br />\nIl suffit d'en cr\u00e9er un en cliquant sur \"**New**\" en haut \u00e0 droite.\n\n![Liste et cr\u00e9ation des notebook](img/EMR_jupyterhub_creer_notebooks.png)\n\nIl est \u00e9galement possible d'en <u>uploader un directement dans notre **bucket S3**</u>.\n\nGrace \u00e0 la <u>**persistance** param\u00e9tr\u00e9e \u00e0 l'instanciation du cluster <br />\nnous sommes actuellement dans l'arborescence de notre **bucket S3**</u>\n\n![Notebook stock\u00e9s sur S3](img/EMR_jupyterhub_S3.png)\n\nJe d\u00e9cide d'**importer un notebook d\u00e9j\u00e0 r\u00e9dig\u00e9 en local directement <br />\nsur S3** et je l'ouvre depuis **l'interface JupyterHub**.\n\n## 4.10 Ex\u00e9cution du code\n\nJe d\u00e9cide d'ex\u00e9cuter cette partie du code depuis **JupyterHub h\u00e9berg\u00e9 sur notre cluster EMR**.<br />\nPour ne pas alourdir inutilement les explications du **notebook**, je ne r\u00e9expliquerai pas les \u00e9tapes communes <br />\nque nous avons d\u00e9j\u00e0 vues dans la premi\u00e8re partie o\u00f9 l'on a ex\u00e9cut\u00e9 le code localement sur notre machine virtuelle Ubuntu.\n\n<u>Avant de commencer</u>, il faut s'assurer d'utiliser le **kernel pyspark**.\n\n**En utilisant ce kernel, une session spark est cr\u00e9\u00e9 \u00e0 l'ex\u00e9cution de la premi\u00e8re cellule**. <br />\nIl n'est donc **plus n\u00e9cessaire d'ex\u00e9cuter le code \"spark = (SparkSession ...\"** comme lors <br />\nde l'ex\u00e9cution de notre notebook en local sur notre VM Ubuntu."}, {"metadata": {"id": "4e759c1e"}, "id": "4e759c1e", "cell_type": "markdown", "source": "### 4.10.1 D\u00e9marrage de la session Spark"}, {"metadata": {"colab": {"referenced_widgets": [""]}, "id": "e5f0fbe1", "outputId": "05a4324a-c810-4e03-e2eb-03e880a3c213", "trusted": true}, "id": "e5f0fbe1", "cell_type": "code", "source": "# L'ex\u00e9cution de cette cellule d\u00e9marre l'application Spark", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "Starting Spark application\n", "name": "stdout"}, {"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<table>\n<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>0</td><td>application_1718364630250_0001</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-22-235.eu-north-1.compute.internal:20888/proxy/application_1718364630250_0001/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-31-167.eu-north-1.compute.internal:8042/node/containerlogs/container_1718364630250_0001_01_000001/livy\">Link</a></td><td>None</td><td>\u2714</td></tr></table>"}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "SparkSession available as 'spark'.\n", "name": "stdout"}, {"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}]}, {"metadata": {"id": "3aba202f"}, "id": "3aba202f", "cell_type": "markdown", "source": "<u>Affichage des informations sur la session en cours et liens vers Spark UI</u> :"}, {"metadata": {"id": "fb788991", "outputId": "4b8521d9-e812-4a36-cc4f-b056353f66ae", "trusted": true}, "id": "fb788991", "cell_type": "code", "source": "%%info", "execution_count": 3, "outputs": [{"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "Current session configs: <tt>{'driverMemory': '1000M', 'executorCores': 2, 'proxyUser': 'jovyan', 'kind': 'pyspark'}</tt><br>"}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<table>\n<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>0</td><td>application_1718364630250_0001</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-22-235.eu-north-1.compute.internal:20888/proxy/application_1718364630250_0001/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-31-167.eu-north-1.compute.internal:8042/node/containerlogs/container_1718364630250_0001_01_000001/livy\">Link</a></td><td>None</td><td>\u2714</td></tr></table>"}, "metadata": {}}]}, {"metadata": {"id": "27ac9832"}, "id": "27ac9832", "cell_type": "markdown", "source": "### 4.10.2 Installation des packages\n\nLes packages n\u00e9cessaires ont \u00e9t\u00e9 install\u00e9 via l'\u00e9tape de **bootstrap** \u00e0 l'instanciation du serveur.\n\n### 4.10.3 Import des librairies"}, {"metadata": {"trusted": true}, "id": "040f9308", "cell_type": "code", "source": "import pandas as pd", "execution_count": 2, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}]}, {"metadata": {"trusted": false}, "id": "274e64f1", "cell_type": "code", "source": "%pip install pandas==1.2.5", "execution_count": 9, "outputs": [{"output_type": "stream", "text": "The code failed because of a fatal error:\n\tFailed to register auto viz for notebook.\nException details:\n\t\"cannot import name 'DataError' from 'pandas.core.groupby' (/opt/mamba/lib/python3.9/site-packages/pandas/core/groupby/__init__.py)\".\n\nSome things to try:\na) Make sure Spark has enough available resources for Jupyter to create a Spark context.\nb) Contact your Jupyter administrator to make sure the Spark magics library is configured correctly.\nc) Restart the kernel.\n", "name": "stderr"}]}, {"metadata": {"trusted": true}, "id": "505cf6ac", "cell_type": "code", "source": "import numpy as np\nimport io\nimport os\nimport tensorflow as tf\nfrom PIL import Image", "execution_count": 4, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}]}, {"metadata": {"colab": {"referenced_widgets": [""]}, "id": "ad562eab", "outputId": "c33b3981-75a8-4250-dcdf-43ea85886a0a", "trusted": true}, "id": "ad562eab", "cell_type": "code", "source": "from keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\nfrom keras.preprocessing.image import img_to_array\nfrom keras import Model\nfrom pyspark.sql.functions import col, pandas_udf, PandasUDFType, element_at, split", "execution_count": 5, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}]}, {"metadata": {"trusted": false}, "id": "1d757e3d", "cell_type": "code", "source": "print(tf.__version__)", "execution_count": 5, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "2.11.0", "name": "stdout"}]}, {"metadata": {"trusted": false}, "id": "936a1d7f", "cell_type": "code", "source": "%pip show pandas", "execution_count": 3, "outputs": [{"output_type": "stream", "text": "Name: pandas\nVersion: 1.2.5\nSummary: Powerful data structures for data analysis, time series, and statistics\nHome-page: https://pandas.pydata.org\nAuthor: \nAuthor-email: \nLicense: BSD\nLocation: /opt/mamba/lib/python3.9/site-packages\nRequires: numpy, python-dateutil, pytz\nRequired-by: autovizwidget, hdijupyterutils, sparkmagic\nNote: you may need to restart the kernel to use updated packages.\n", "name": "stdout"}]}, {"metadata": {"id": "83663cbd"}, "id": "83663cbd", "cell_type": "markdown", "source": "### 4.10.4 D\u00e9finition des PATH pour charger les images et enregistrer les r\u00e9sultats\n\nNous acc\u00e9dons directement \u00e0 nos **donn\u00e9es sur S3** comme si elles \u00e9taient **stock\u00e9es localement**."}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "46be859d", "outputId": "c24bc9bf-5ad8-4f85-88c3-5aa0ac93640c", "trusted": true}, "id": "46be859d", "cell_type": "code", "source": "PATH = 's3://p8-lucasdata'\nPATH_Data = PATH+'/Test'\nPATH_Result = PATH+'/Results'\nprint('PATH:        '+\\\n      PATH+'\\nPATH_Data:   '+\\\n      PATH_Data+'\\nPATH_Result: '+PATH_Result)", "execution_count": 6, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "PATH:        s3://p8-lucasdata\nPATH_Data:   s3://p8-lucasdata/Test\nPATH_Result: s3://p8-lucasdata/Results", "name": "stdout"}]}, {"metadata": {"id": "cf883c20"}, "id": "cf883c20", "cell_type": "markdown", "source": "### 4.10.5 Traitement des donn\u00e9es"}, {"metadata": {"id": "2ffe93f5"}, "id": "2ffe93f5", "cell_type": "markdown", "source": "#### 4.10.5.1 Chargement des donn\u00e9es"}, {"metadata": {"colab": {"referenced_widgets": [""]}, "id": "7e4b319a", "outputId": "7eb88315-578e-4ac3-b786-edfb83de318e", "trusted": true}, "id": "7e4b319a", "cell_type": "code", "source": "images = spark.read.format(\"binaryFile\") \\\n  .option(\"pathGlobFilter\", \"*.jpg\") \\\n  .option(\"recursiveFileLookup\", \"true\") \\\n  .load(PATH_Data)", "execution_count": 7, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}]}, {"metadata": {"colab": {"referenced_widgets": [""]}, "id": "16bfeb4d", "outputId": "af2c7ed6-0f54-4f7f-cc5c-c416db5fc999", "trusted": true}, "id": "16bfeb4d", "cell_type": "code", "source": "images.show(5)", "execution_count": 8, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "+--------------------+-------------------+------+--------------------+\n|                path|   modificationTime|length|             content|\n+--------------------+-------------------+------+--------------------+\n|s3://p8-lucasdata...|2024-06-12 09:44:20|  7353|[FF D8 FF E0 00 1...|\n|s3://p8-lucasdata...|2024-06-12 09:44:20|  7350|[FF D8 FF E0 00 1...|\n|s3://p8-lucasdata...|2024-06-12 09:44:20|  7349|[FF D8 FF E0 00 1...|\n|s3://p8-lucasdata...|2024-06-12 09:44:20|  7348|[FF D8 FF E0 00 1...|\n|s3://p8-lucasdata...|2024-06-12 09:44:21|  7328|[FF D8 FF E0 00 1...|\n+--------------------+-------------------+------+--------------------+\nonly showing top 5 rows", "name": "stdout"}]}, {"metadata": {"id": "8b32ac34"}, "id": "8b32ac34", "cell_type": "markdown", "source": "<u>Je ne conserve que le **path** de l'image et j'ajoute <br />\n    une colonne contenant les **labels** de chaque image</u> :"}, {"metadata": {"colab": {"referenced_widgets": [""]}, "id": "a52ab808", "outputId": "e678aa54-2835-4aa3-f2dd-30dff06b6a53", "trusted": true}, "id": "a52ab808", "cell_type": "code", "source": "images = images.withColumn('label', element_at(split(images['path'], '/'),-2))\nprint(images.printSchema())\nprint(images.select('path','label').show(5,False))", "execution_count": 9, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "root\n |-- path: string (nullable = true)\n |-- modificationTime: timestamp (nullable = true)\n |-- length: long (nullable = true)\n |-- content: binary (nullable = true)\n |-- label: string (nullable = true)\n\nNone\n+-----------------------------------------------+----------+\n|path                                           |label     |\n+-----------------------------------------------+----------+\n|s3://p8-lucasdata/Test/Watermelon/r_106_100.jpg|Watermelon|\n|s3://p8-lucasdata/Test/Watermelon/r_109_100.jpg|Watermelon|\n|s3://p8-lucasdata/Test/Watermelon/r_108_100.jpg|Watermelon|\n|s3://p8-lucasdata/Test/Watermelon/r_107_100.jpg|Watermelon|\n|s3://p8-lucasdata/Test/Watermelon/r_95_100.jpg |Watermelon|\n+-----------------------------------------------+----------+\nonly showing top 5 rows\n\nNone", "name": "stdout"}]}, {"metadata": {"id": "8f15b199"}, "id": "8f15b199", "cell_type": "markdown", "source": "#### 4.10.5.2 Pr\u00e9paration du mod\u00e8le"}, {"metadata": {"colab": {"referenced_widgets": [""]}, "id": "ec7c7165", "outputId": "e0030d05-da51-4c83-e320-d8a796582e09", "trusted": true}, "id": "ec7c7165", "cell_type": "code", "source": "model = MobileNetV2(weights='imagenet',\n                    include_top=True,\n                    input_shape=(224, 224, 3))", "execution_count": 10, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224.h5\n\r\u001b[1m       0/14536120\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m0s\u001b[0m 0s/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m   49152/14536120\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m27s\u001b[0m 2us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m   81920/14536120\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m33s\u001b[0m 2us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m 2596864/14536120\u001b[0m \u001b[32m\u2501\u2501\u2501\u001b[0m\u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m1s\u001b[0m 0us/step \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m 3842048/14536120\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m0s\u001b[0m 0us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m 5062656/14536120\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m0s\u001b[0m 0us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m 6955008/14536120\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m0s\u001b[0m 0us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m 7462912/14536120\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m0s\u001b[0m 0us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11190272/14536120\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m0s\u001b[0m 0us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m12296192/14536120\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m0s\u001b[0m 0us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m14536120/14536120\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step", "name": "stdout"}]}, {"metadata": {"colab": {"referenced_widgets": [""]}, "id": "1b9bc650", "outputId": "737408e9-23d7-4525-b113-f660b9247a1c", "trusted": true}, "id": "1b9bc650", "cell_type": "code", "source": "new_model = Model(inputs=model.input,\n                  outputs=model.layers[-2].output)", "execution_count": 11, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}]}, {"metadata": {"colab": {"referenced_widgets": [""]}, "id": "a0d497f2", "outputId": "60ded3e9-e580-44e6-946a-642e0ede4427", "trusted": true}, "id": "a0d497f2", "cell_type": "code", "source": "brodcast_weights = sc.broadcast(new_model.get_weights())", "execution_count": 12, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}]}, {"metadata": {"colab": {"referenced_widgets": [""]}, "id": "1bc0bf14", "outputId": "40e9fdeb-068d-4c84-f3a0-24a8c6695a0f", "trusted": true}, "id": "1bc0bf14", "cell_type": "code", "source": "new_model.summary()", "execution_count": 13, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "Model: \"functional_1\"\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Layer (type)        \u2503 Output Shape      \u2503    Param # \u2503 Connected to      \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 input_layer         \u2502 (None, 224, 224,  \u2502          0 \u2502 -                 \u2502\n\u2502 (InputLayer)        \u2502 3)                \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Conv1 (Conv2D)      \u2502 (None, 112, 112,  \u2502        864 \u2502 input_layer[0][0] \u2502\n\u2502                     \u2502 32)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 bn_Conv1            \u2502 (None, 112, 112,  \u2502        128 \u2502 Conv1[0][0]       \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 32)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Conv1_relu (ReLU)   \u2502 (None, 112, 112,  \u2502          0 \u2502 bn_Conv1[0][0]    \u2502\n\u2502                     \u2502 32)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 expanded_conv_dept\u2026 \u2502 (None, 112, 112,  \u2502        288 \u2502 Conv1_relu[0][0]  \u2502\n\u2502 (DepthwiseConv2D)   \u2502 32)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 expanded_conv_dept\u2026 \u2502 (None, 112, 112,  \u2502        128 \u2502 expanded_conv_de\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 32)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 expanded_conv_dept\u2026 \u2502 (None, 112, 112,  \u2502          0 \u2502 expanded_conv_de\u2026 \u2502\n\u2502 (ReLU)              \u2502 32)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 expanded_conv_proj\u2026 \u2502 (None, 112, 112,  \u2502        512 \u2502 expanded_conv_de\u2026 \u2502\n\u2502 (Conv2D)            \u2502 16)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 expanded_conv_proj\u2026 \u2502 (None, 112, 112,  \u2502         64 \u2502 expanded_conv_pr\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 16)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_1_expand      \u2502 (None, 112, 112,  \u2502      1,536 \u2502 expanded_conv_pr\u2026 \u2502\n\u2502 (Conv2D)            \u2502 96)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_1_expand_BN   \u2502 (None, 112, 112,  \u2502        384 \u2502 block_1_expand[0\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 96)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_1_expand_relu \u2502 (None, 112, 112,  \u2502          0 \u2502 block_1_expand_B\u2026 \u2502\n\u2502 (ReLU)              \u2502 96)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_1_pad         \u2502 (None, 113, 113,  \u2502          0 \u2502 block_1_expand_r\u2026 \u2502\n\u2502 (ZeroPadding2D)     \u2502 96)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_1_depthwise   \u2502 (None, 56, 56,    \u2502        864 \u2502 block_1_pad[0][0] \u2502\n\u2502 (DepthwiseConv2D)   \u2502 96)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_1_depthwise_\u2026 \u2502 (None, 56, 56,    \u2502        384 \u2502 block_1_depthwis\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 96)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_1_depthwise_\u2026 \u2502 (None, 56, 56,    \u2502          0 \u2502 block_1_depthwis\u2026 \u2502\n\u2502 (ReLU)              \u2502 96)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_1_project     \u2502 (None, 56, 56,    \u2502      2,304 \u2502 block_1_depthwis\u2026 \u2502\n\u2502 (Conv2D)            \u2502 24)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_1_project_BN  \u2502 (None, 56, 56,    \u2502         96 \u2502 block_1_project[\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 24)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_2_expand      \u2502 (None, 56, 56,    \u2502      3,456 \u2502 block_1_project_\u2026 \u2502\n\u2502 (Conv2D)            \u2502 144)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_2_expand_BN   \u2502 (None, 56, 56,    \u2502        576 \u2502 block_2_expand[0\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 144)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_2_expand_relu \u2502 (None, 56, 56,    \u2502          0 \u2502 block_2_expand_B\u2026 \u2502\n\u2502 (ReLU)              \u2502 144)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_2_depthwise   \u2502 (None, 56, 56,    \u2502      1,296 \u2502 block_2_expand_r\u2026 \u2502\n\u2502 (DepthwiseConv2D)   \u2502 144)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_2_depthwise_\u2026 \u2502 (None, 56, 56,    \u2502        576 \u2502 block_2_depthwis\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 144)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_2_depthwise_\u2026 \u2502 (None, 56, 56,    \u2502          0 \u2502 block_2_depthwis\u2026 \u2502\n\u2502 (ReLU)              \u2502 144)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_2_project     \u2502 (None, 56, 56,    \u2502      3,456 \u2502 block_2_depthwis\u2026 \u2502\n\u2502 (Conv2D)            \u2502 24)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_2_project_BN  \u2502 (None, 56, 56,    \u2502         96 \u2502 block_2_project[\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 24)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_2_add (Add)   \u2502 (None, 56, 56,    \u2502          0 \u2502 block_1_project_\u2026 \u2502\n\u2502                     \u2502 24)               \u2502            \u2502 block_2_project_\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_3_expand      \u2502 (None, 56, 56,    \u2502      3,456 \u2502 block_2_add[0][0] \u2502\n\u2502 (Conv2D)            \u2502 144)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_3_expand_BN   \u2502 (None, 56, 56,    \u2502        576 \u2502 block_3_expand[0\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 144)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_3_expand_relu \u2502 (None, 56, 56,    \u2502          0 \u2502 block_3_expand_B\u2026 \u2502\n\u2502 (ReLU)              \u2502 144)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_3_pad         \u2502 (None, 57, 57,    \u2502          0 \u2502 block_3_expand_r\u2026 \u2502\n\u2502 (ZeroPadding2D)     \u2502 144)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_3_depthwise   \u2502 (None, 28, 28,    \u2502      1,296 \u2502 block_3_pad[0][0] \u2502\n\u2502 (DepthwiseConv2D)   \u2502 144)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_3_depthwise_\u2026 \u2502 (None, 28, 28,    \u2502        576 \u2502 block_3_depthwis\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 144)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_3_depthwise_\u2026 \u2502 (None, 28, 28,    \u2502          0 \u2502 block_3_depthwis\u2026 \u2502\n\u2502 (ReLU)              \u2502 144)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_3_project     \u2502 (None, 28, 28,    \u2502      4,608 \u2502 block_3_depthwis\u2026 \u2502\n\u2502 (Conv2D)            \u2502 32)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_3_project_BN  \u2502 (None, 28, 28,    \u2502        128 \u2502 block_3_project[\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 32)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_4_expand      \u2502 (None, 28, 28,    \u2502      6,144 \u2502 block_3_project_\u2026 \u2502\n\u2502 (Conv2D)            \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_4_expand_BN   \u2502 (None, 28, 28,    \u2502        768 \u2502 block_4_expand[0\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_4_expand_relu \u2502 (None, 28, 28,    \u2502          0 \u2502 block_4_expand_B\u2026 \u2502\n\u2502 (ReLU)              \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_4_depthwise   \u2502 (None, 28, 28,    \u2502      1,728 \u2502 block_4_expand_r\u2026 \u2502\n\u2502 (DepthwiseConv2D)   \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_4_depthwise_\u2026 \u2502 (None, 28, 28,    \u2502        768 \u2502 block_4_depthwis\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_4_depthwise_\u2026 \u2502 (None, 28, 28,    \u2502          0 \u2502 block_4_depthwis\u2026 \u2502\n\u2502 (ReLU)              \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_4_project     \u2502 (None, 28, 28,    \u2502      6,144 \u2502 block_4_depthwis\u2026 \u2502\n\u2502 (Conv2D)            \u2502 32)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_4_project_BN  \u2502 (None, 28, 28,    \u2502        128 \u2502 block_4_project[\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 32)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_4_add (Add)   \u2502 (None, 28, 28,    \u2502          0 \u2502 block_3_project_\u2026 \u2502\n\u2502                     \u2502 32)               \u2502            \u2502 block_4_project_\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_5_expand      \u2502 (None, 28, 28,    \u2502      6,144 \u2502 block_4_add[0][0] \u2502\n\u2502 (Conv2D)            \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_5_expand_BN   \u2502 (None, 28, 28,    \u2502        768 \u2502 block_5_expand[0\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_5_expand_relu \u2502 (None, 28, 28,    \u2502          0 \u2502 block_5_expand_B\u2026 \u2502\n\u2502 (ReLU)              \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_5_depthwise   \u2502 (None, 28, 28,    \u2502      1,728 \u2502 block_5_expand_r\u2026 \u2502\n\u2502 (DepthwiseConv2D)   \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_5_depthwise_\u2026 \u2502 (None, 28, 28,    \u2502        768 \u2502 block_5_depthwis\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_5_depthwise_\u2026 \u2502 (None, 28, 28,    \u2502          0 \u2502 block_5_depthwis\u2026 \u2502\n\u2502 (ReLU)              \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_5_project     \u2502 (None, 28, 28,    \u2502      6,144 \u2502 block_5_depthwis\u2026 \u2502\n\u2502 (Conv2D)            \u2502 32)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_5_project_BN  \u2502 (None, 28, 28,    \u2502        128 \u2502 block_5_project[\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 32)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_5_add (Add)   \u2502 (None, 28, 28,    \u2502          0 \u2502 block_4_add[0][0\u2026 \u2502\n\u2502                     \u2502 32)               \u2502            \u2502 block_5_project_\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_6_expand      \u2502 (None, 28, 28,    \u2502      6,144 \u2502 block_5_add[0][0] \u2502\n\u2502 (Conv2D)            \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_6_expand_BN   \u2502 (None, 28, 28,    \u2502        768 \u2502 block_6_expand[0\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_6_expand_relu \u2502 (None, 28, 28,    \u2502          0 \u2502 block_6_expand_B\u2026 \u2502\n\u2502 (ReLU)              \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_6_pad         \u2502 (None, 29, 29,    \u2502          0 \u2502 block_6_expand_r\u2026 \u2502\n\u2502 (ZeroPadding2D)     \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_6_depthwise   \u2502 (None, 14, 14,    \u2502      1,728 \u2502 block_6_pad[0][0] \u2502\n\u2502 (DepthwiseConv2D)   \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_6_depthwise_\u2026 \u2502 (None, 14, 14,    \u2502        768 \u2502 block_6_depthwis\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_6_depthwise_\u2026 \u2502 (None, 14, 14,    \u2502          0 \u2502 block_6_depthwis\u2026 \u2502\n\u2502 (ReLU)              \u2502 192)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_6_project     \u2502 (None, 14, 14,    \u2502     12,288 \u2502 block_6_depthwis\u2026 \u2502\n\u2502 (Conv2D)            \u2502 64)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_6_project_BN  \u2502 (None, 14, 14,    \u2502        256 \u2502 block_6_project[\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 64)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_7_expand      \u2502 (None, 14, 14,    \u2502     24,576 \u2502 block_6_project_\u2026 \u2502\n\u2502 (Conv2D)            \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_7_expand_BN   \u2502 (None, 14, 14,    \u2502      1,536 \u2502 block_7_expand[0\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_7_expand_relu \u2502 (None, 14, 14,    \u2502          0 \u2502 block_7_expand_B\u2026 \u2502\n\u2502 (ReLU)              \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_7_depthwise   \u2502 (None, 14, 14,    \u2502      3,456 \u2502 block_7_expand_r\u2026 \u2502\n\u2502 (DepthwiseConv2D)   \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_7_depthwise_\u2026 \u2502 (None, 14, 14,    \u2502      1,536 \u2502 block_7_depthwis\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_7_depthwise_\u2026 \u2502 (None, 14, 14,    \u2502          0 \u2502 block_7_depthwis\u2026 \u2502\n\u2502 (ReLU)              \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_7_project     \u2502 (None, 14, 14,    \u2502     24,576 \u2502 block_7_depthwis\u2026 \u2502\n\u2502 (Conv2D)            \u2502 64)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_7_project_BN  \u2502 (None, 14, 14,    \u2502        256 \u2502 block_7_project[\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 64)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_7_add (Add)   \u2502 (None, 14, 14,    \u2502          0 \u2502 block_6_project_\u2026 \u2502\n\u2502                     \u2502 64)               \u2502            \u2502 block_7_project_\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_8_expand      \u2502 (None, 14, 14,    \u2502     24,576 \u2502 block_7_add[0][0] \u2502\n\u2502 (Conv2D)            \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_8_expand_BN   \u2502 (None, 14, 14,    \u2502      1,536 \u2502 block_8_expand[0\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_8_expand_relu \u2502 (None, 14, 14,    \u2502          0 \u2502 block_8_expand_B\u2026 \u2502\n\u2502 (ReLU)              \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_8_depthwise   \u2502 (None, 14, 14,    \u2502      3,456 \u2502 block_8_expand_r\u2026 \u2502\n\u2502 (DepthwiseConv2D)   \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_8_depthwise_\u2026 \u2502 (None, 14, 14,    \u2502      1,536 \u2502 block_8_depthwis\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_8_depthwise_\u2026 \u2502 (None, 14, 14,    \u2502          0 \u2502 block_8_depthwis\u2026 \u2502\n\u2502 (ReLU)              \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_8_project     \u2502 (None, 14, 14,    \u2502     24,576 \u2502 block_8_depthwis\u2026 \u2502\n\u2502 (Conv2D)            \u2502 64)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_8_project_BN  \u2502 (None, 14, 14,    \u2502        256 \u2502 block_8_project[\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 64)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_8_add (Add)   \u2502 (None, 14, 14,    \u2502          0 \u2502 block_7_add[0][0\u2026 \u2502\n\u2502                     \u2502 64)               \u2502            \u2502 block_8_project_\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_9_expand      \u2502 (None, 14, 14,    \u2502     24,576 \u2502 block_8_add[0][0] \u2502\n\u2502 (Conv2D)            \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_9_expand_BN   \u2502 (None, 14, 14,    \u2502      1,536 \u2502 block_9_expand[0\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_9_expand_relu \u2502 (None, 14, 14,    \u2502          0 \u2502 block_9_expand_B\u2026 \u2502\n\u2502 (ReLU)              \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_9_depthwise   \u2502 (None, 14, 14,    \u2502      3,456 \u2502 block_9_expand_r\u2026 \u2502\n\u2502 (DepthwiseConv2D)   \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_9_depthwise_\u2026 \u2502 (None, 14, 14,    \u2502      1,536 \u2502 block_9_depthwis\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_9_depthwise_\u2026 \u2502 (None, 14, 14,    \u2502          0 \u2502 block_9_depthwis\u2026 \u2502\n\u2502 (ReLU)              \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_9_project     \u2502 (None, 14, 14,    \u2502     24,576 \u2502 block_9_depthwis\u2026 \u2502\n\u2502 (Conv2D)            \u2502 64)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_9_project_BN  \u2502 (None, 14, 14,    \u2502        256 \u2502 block_9_project[\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 64)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_9_add (Add)   \u2502 (None, 14, 14,    \u2502          0 \u2502 block_8_add[0][0\u2026 \u2502\n\u2502                     \u2502 64)               \u2502            \u2502 block_9_project_\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_10_expand     \u2502 (None, 14, 14,    \u2502     24,576 \u2502 block_9_add[0][0] \u2502\n\u2502 (Conv2D)            \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_10_expand_BN  \u2502 (None, 14, 14,    \u2502      1,536 \u2502 block_10_expand[\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_10_expand_re\u2026 \u2502 (None, 14, 14,    \u2502          0 \u2502 block_10_expand_\u2026 \u2502\n\u2502 (ReLU)              \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_10_depthwise  \u2502 (None, 14, 14,    \u2502      3,456 \u2502 block_10_expand_\u2026 \u2502\n\u2502 (DepthwiseConv2D)   \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_10_depthwise\u2026 \u2502 (None, 14, 14,    \u2502      1,536 \u2502 block_10_depthwi\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_10_depthwise\u2026 \u2502 (None, 14, 14,    \u2502          0 \u2502 block_10_depthwi\u2026 \u2502\n\u2502 (ReLU)              \u2502 384)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_10_project    \u2502 (None, 14, 14,    \u2502     36,864 \u2502 block_10_depthwi\u2026 \u2502\n\u2502 (Conv2D)            \u2502 96)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_10_project_BN \u2502 (None, 14, 14,    \u2502        384 \u2502 block_10_project\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 96)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_11_expand     \u2502 (None, 14, 14,    \u2502     55,296 \u2502 block_10_project\u2026 \u2502\n\u2502 (Conv2D)            \u2502 576)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_11_expand_BN  \u2502 (None, 14, 14,    \u2502      2,304 \u2502 block_11_expand[\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 576)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_11_expand_re\u2026 \u2502 (None, 14, 14,    \u2502          0 \u2502 block_11_expand_\u2026 \u2502\n\u2502 (ReLU)              \u2502 576)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_11_depthwise  \u2502 (None, 14, 14,    \u2502      5,184 \u2502 block_11_expand_\u2026 \u2502\n\u2502 (DepthwiseConv2D)   \u2502 576)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_11_depthwise\u2026 \u2502 (None, 14, 14,    \u2502      2,304 \u2502 block_11_depthwi\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 576)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_11_depthwise\u2026 \u2502 (None, 14, 14,    \u2502          0 \u2502 block_11_depthwi\u2026 \u2502\n\u2502 (ReLU)              \u2502 576)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_11_project    \u2502 (None, 14, 14,    \u2502     55,296 \u2502 block_11_depthwi\u2026 \u2502\n\u2502 (Conv2D)            \u2502 96)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_11_project_BN \u2502 (None, 14, 14,    \u2502        384 \u2502 block_11_project\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 96)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_11_add (Add)  \u2502 (None, 14, 14,    \u2502          0 \u2502 block_10_project\u2026 \u2502\n\u2502                     \u2502 96)               \u2502            \u2502 block_11_project\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_12_expand     \u2502 (None, 14, 14,    \u2502     55,296 \u2502 block_11_add[0][\u2026 \u2502\n\u2502 (Conv2D)            \u2502 576)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_12_expand_BN  \u2502 (None, 14, 14,    \u2502      2,304 \u2502 block_12_expand[\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 576)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_12_expand_re\u2026 \u2502 (None, 14, 14,    \u2502          0 \u2502 block_12_expand_\u2026 \u2502\n\u2502 (ReLU)              \u2502 576)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_12_depthwise  \u2502 (None, 14, 14,    \u2502      5,184 \u2502 block_12_expand_\u2026 \u2502\n\u2502 (DepthwiseConv2D)   \u2502 576)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_12_depthwise\u2026 \u2502 (None, 14, 14,    \u2502      2,304 \u2502 block_12_depthwi\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 576)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_12_depthwise\u2026 \u2502 (None, 14, 14,    \u2502          0 \u2502 block_12_depthwi\u2026 \u2502\n\u2502 (ReLU)              \u2502 576)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_12_project    \u2502 (None, 14, 14,    \u2502     55,296 \u2502 block_12_depthwi\u2026 \u2502\n\u2502 (Conv2D)            \u2502 96)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_12_project_BN \u2502 (None, 14, 14,    \u2502        384 \u2502 block_12_project\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 96)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_12_add (Add)  \u2502 (None, 14, 14,    \u2502          0 \u2502 block_11_add[0][\u2026 \u2502\n\u2502                     \u2502 96)               \u2502            \u2502 block_12_project\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_13_expand     \u2502 (None, 14, 14,    \u2502     55,296 \u2502 block_12_add[0][\u2026 \u2502\n\u2502 (Conv2D)            \u2502 576)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_13_expand_BN  \u2502 (None, 14, 14,    \u2502      2,304 \u2502 block_13_expand[\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 576)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_13_expand_re\u2026 \u2502 (None, 14, 14,    \u2502          0 \u2502 block_13_expand_\u2026 \u2502\n\u2502 (ReLU)              \u2502 576)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_13_pad        \u2502 (None, 15, 15,    \u2502          0 \u2502 block_13_expand_\u2026 \u2502\n\u2502 (ZeroPadding2D)     \u2502 576)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_13_depthwise  \u2502 (None, 7, 7, 576) \u2502      5,184 \u2502 block_13_pad[0][\u2026 \u2502\n\u2502 (DepthwiseConv2D)   \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_13_depthwise\u2026 \u2502 (None, 7, 7, 576) \u2502      2,304 \u2502 block_13_depthwi\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_13_depthwise\u2026 \u2502 (None, 7, 7, 576) \u2502          0 \u2502 block_13_depthwi\u2026 \u2502\n\u2502 (ReLU)              \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_13_project    \u2502 (None, 7, 7, 160) \u2502     92,160 \u2502 block_13_depthwi\u2026 \u2502\n\u2502 (Conv2D)            \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_13_project_BN \u2502 (None, 7, 7, 160) \u2502        640 \u2502 block_13_project\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_14_expand     \u2502 (None, 7, 7, 960) \u2502    153,600 \u2502 block_13_project\u2026 \u2502\n\u2502 (Conv2D)            \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_14_expand_BN  \u2502 (None, 7, 7, 960) \u2502      3,840 \u2502 block_14_expand[\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_14_expand_re\u2026 \u2502 (None, 7, 7, 960) \u2502          0 \u2502 block_14_expand_\u2026 \u2502\n\u2502 (ReLU)              \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_14_depthwise  \u2502 (None, 7, 7, 960) \u2502      8,640 \u2502 block_14_expand_\u2026 \u2502\n\u2502 (DepthwiseConv2D)   \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_14_depthwise\u2026 \u2502 (None, 7, 7, 960) \u2502      3,840 \u2502 block_14_depthwi\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_14_depthwise\u2026 \u2502 (None, 7, 7, 960) \u2502          0 \u2502 block_14_depthwi\u2026 \u2502\n\u2502 (ReLU)              \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_14_project    \u2502 (None, 7, 7, 160) \u2502    153,600 \u2502 block_14_depthwi\u2026 \u2502\n\u2502 (Conv2D)            \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_14_project_BN \u2502 (None, 7, 7, 160) \u2502        640 \u2502 block_14_project\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_14_add (Add)  \u2502 (None, 7, 7, 160) \u2502          0 \u2502 block_13_project\u2026 \u2502\n\u2502                     \u2502                   \u2502            \u2502 block_14_project\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_15_expand     \u2502 (None, 7, 7, 960) \u2502    153,600 \u2502 block_14_add[0][\u2026 \u2502\n\u2502 (Conv2D)            \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_15_expand_BN  \u2502 (None, 7, 7, 960) \u2502      3,840 \u2502 block_15_expand[\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_15_expand_re\u2026 \u2502 (None, 7, 7, 960) \u2502          0 \u2502 block_15_expand_\u2026 \u2502\n\u2502 (ReLU)              \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_15_depthwise  \u2502 (None, 7, 7, 960) \u2502      8,640 \u2502 block_15_expand_\u2026 \u2502\n\u2502 (DepthwiseConv2D)   \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_15_depthwise\u2026 \u2502 (None, 7, 7, 960) \u2502      3,840 \u2502 block_15_depthwi\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_15_depthwise\u2026 \u2502 (None, 7, 7, 960) \u2502          0 \u2502 block_15_depthwi\u2026 \u2502\n\u2502 (ReLU)              \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_15_project    \u2502 (None, 7, 7, 160) \u2502    153,600 \u2502 block_15_depthwi\u2026 \u2502\n\u2502 (Conv2D)            \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_15_project_BN \u2502 (None, 7, 7, 160) \u2502        640 \u2502 block_15_project\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_15_add (Add)  \u2502 (None, 7, 7, 160) \u2502          0 \u2502 block_14_add[0][\u2026 \u2502\n\u2502                     \u2502                   \u2502            \u2502 block_15_project\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_16_expand     \u2502 (None, 7, 7, 960) \u2502    153,600 \u2502 block_15_add[0][\u2026 \u2502\n\u2502 (Conv2D)            \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_16_expand_BN  \u2502 (None, 7, 7, 960) \u2502      3,840 \u2502 block_16_expand[\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_16_expand_re\u2026 \u2502 (None, 7, 7, 960) \u2502          0 \u2502 block_16_expand_\u2026 \u2502\n\u2502 (ReLU)              \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_16_depthwise  \u2502 (None, 7, 7, 960) \u2502      8,640 \u2502 block_16_expand_\u2026 \u2502\n\u2502 (DepthwiseConv2D)   \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_16_depthwise\u2026 \u2502 (None, 7, 7, 960) \u2502      3,840 \u2502 block_16_depthwi\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_16_depthwise\u2026 \u2502 (None, 7, 7, 960) \u2502          0 \u2502 block_16_depthwi\u2026 \u2502\n\u2502 (ReLU)              \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_16_project    \u2502 (None, 7, 7, 320) \u2502    307,200 \u2502 block_16_depthwi\u2026 \u2502\n\u2502 (Conv2D)            \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_16_project_BN \u2502 (None, 7, 7, 320) \u2502      1,280 \u2502 block_16_project\u2026 \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Conv_1 (Conv2D)     \u2502 (None, 7, 7,      \u2502    409,600 \u2502 block_16_project\u2026 \u2502\n\u2502                     \u2502 1280)             \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Conv_1_bn           \u2502 (None, 7, 7,      \u2502      5,120 \u2502 Conv_1[0][0]      \u2502\n\u2502 (BatchNormalizatio\u2026 \u2502 1280)             \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 out_relu (ReLU)     \u2502 (None, 7, 7,      \u2502          0 \u2502 Conv_1_bn[0][0]   \u2502\n\u2502                     \u2502 1280)             \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 global_average_poo\u2026 \u2502 (None, 1280)      \u2502          0 \u2502 out_relu[0][0]    \u2502\n\u2502 (GlobalAveragePool\u2026 \u2502                   \u2502            \u2502                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n Total params: 2,257,984 (8.61 MB)\n Trainable params: 2,223,872 (8.48 MB)\n Non-trainable params: 34,112 (133.25 KB)", "name": "stdout"}]}, {"metadata": {"colab": {"referenced_widgets": [""]}, "id": "be8fe2b9", "outputId": "0d8b1151-900e-4a3d-a28f-d82cb26893a5", "trusted": true}, "id": "be8fe2b9", "cell_type": "code", "source": "def model_fn():\n    \"\"\"\n    Returns a MobileNetV2 model with top layer removed\n    and broadcasted pretrained weights.\n    \"\"\"\n    model = MobileNetV2(weights='imagenet',\n                        include_top=True,\n                        input_shape=(224, 224, 3))\n    for layer in model.layers:\n        layer.trainable = False\n    new_model = Model(inputs=model.input,\n                  outputs=model.layers[-2].output)\n    new_model.set_weights(brodcast_weights.value)\n    return new_model", "execution_count": 14, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}]}, {"metadata": {"id": "c032f135"}, "id": "c032f135", "cell_type": "markdown", "source": "#### 4.10.5.3 D\u00e9finition du processus de chargement des images <br/> et application de leur featurisation \u00e0 travers l'utilisation de pandas UDF"}, {"metadata": {"scrolled": true, "colab": {"referenced_widgets": [""]}, "id": "933100cf", "outputId": "cf71032a-bb04-4020-d450-243f3e84845e", "trusted": true}, "id": "933100cf", "cell_type": "code", "source": "def preprocess(content):\n    \"\"\"\n    Preprocesses raw image bytes for prediction.\n    \"\"\"\n    img = Image.open(io.BytesIO(content)).resize([224, 224])\n    arr = img_to_array(img)\n    return preprocess_input(arr)\n\ndef featurize_series(model, content_series):\n    \"\"\"\n    Featurize a pd.Series of raw images using the input model.\n    :return: a pd.Series of image features\n    \"\"\"\n    input = np.stack(content_series.map(preprocess))\n    preds = model.predict(input)\n    # For some layers, output features will be multi-dimensional tensors.\n    # We flatten the feature tensors to vectors for easier storage in Spark DataFrames.\n    output = [p.flatten() for p in preds]\n    return pd.Series(output)\n\n@pandas_udf('array<float>', PandasUDFType.SCALAR_ITER)\ndef featurize_udf(content_series_iter):\n    '''\n    This method is a Scalar Iterator pandas UDF wrapping our featurization function.\n    The decorator specifies that this returns a Spark DataFrame column of type ArrayType(FloatType).\n\n    :param content_series_iter: This argument is an iterator over batches of data, where each batch\n                              is a pandas Series of image data.\n    '''\n    # With Scalar Iterator pandas UDFs, we can load the model once and then re-use it\n    # for multiple data batches.  This amortizes the overhead of loading big models.\n    model = model_fn()\n    for content_series in content_series_iter:\n        yield featurize_series(model, content_series)", "execution_count": 15, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "/mnt1/yarn/usercache/livy/appcache/application_1718364630250_0001/container_1718364630250_0001_01_000001/pyspark.zip/pyspark/sql/pandas/functions.py:407: UserWarning: In Python 3.6+ and Spark 3.0+, it is preferred to specify type hints for pandas UDF instead of specifying pandas UDF type which will be deprecated in the future releases. See SPARK-28264 for more details.", "name": "stdout"}]}, {"metadata": {"id": "f23206e8"}, "id": "f23206e8", "cell_type": "markdown", "source": "#### 4.10.5.4 Ex\u00e9cutions des actions d'extractions de features"}, {"metadata": {"colab": {"referenced_widgets": [""]}, "id": "22d760c2", "outputId": "50ae6473-35ea-4aef-fd2b-f049fd9eefea", "trusted": false}, "id": "22d760c2", "cell_type": "code", "source": "# spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"1024\")", "execution_count": null, "outputs": [{"data": {"application/vnd.jupyter.widget-view+json": {"model_id": "", "version_major": 2, "version_minor": 0}, "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026"}, "metadata": {}, "output_type": "display_data"}]}, {"metadata": {"colab": {"referenced_widgets": [""]}, "id": "5e07fd68", "outputId": "699e2f41-1bef-4404-ab38-00a6b3215ba0", "trusted": true}, "id": "5e07fd68", "cell_type": "code", "source": "features_df = images.repartition(24).select(col(\"path\"),\n                                            col(\"label\"),\n                                            featurize_udf(\"content\").alias(\"features\")\n                                           )", "execution_count": 16, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}]}, {"metadata": {"id": "t_gl8Q0Z4JTk"}, "id": "t_gl8Q0Z4JTk", "cell_type": "markdown", "source": "#### 4.10.5.4 R\u00e9duction de dimension"}, {"metadata": {"id": "Lsaum1GQ4JTl"}, "id": "Lsaum1GQ4JTl", "cell_type": "markdown", "source": "Nous allons r\u00e9duire la taille des caract\u00e9ristiques d'images en appliquant une PCA. Pour cela, nous convertir le contenu de la colonne features tout juste cr\u00e9\u00e9e pour analyser le nombre de composante n\u00e9cessaire pour conserver 99.9% de la variance."}, {"metadata": {"id": "Mp7TNAbI4JTl"}, "id": "Mp7TNAbI4JTl", "cell_type": "markdown", "source": "On importe les package pyspark pour le PCA et la vectorisation."}, {"metadata": {"id": "8qsLf-bm4JTm", "trusted": true}, "id": "8qsLf-bm4JTm", "cell_type": "code", "source": "from pyspark.ml.feature import PCA\nfrom pyspark.ml.linalg import Vectors, VectorUDT\nfrom pyspark.sql.functions import udf", "execution_count": 17, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}]}, {"metadata": {"id": "B0e5xued4JTm"}, "id": "B0e5xued4JTm", "cell_type": "markdown", "source": "On vectorise puis fit la pca."}, {"metadata": {"id": "F2Rc7FHH4JTm", "trusted": true}, "id": "F2Rc7FHH4JTm", "cell_type": "code", "source": "# Step 2: Convert features to a Vector column for PCA\nto_vector_udf = udf(lambda r: Vectors.dense(r), VectorUDT())\nfeatures_vector_df = features_df.withColumn(\"features_vector\", to_vector_udf(col(\"features\")))\n\n# Step 3: Apply PCA using PySpark\nn_components = 1280\npca = PCA(k=n_components, inputCol=\"features_vector\", outputCol=\"pca_features\")\npca_model = pca.fit(features_vector_df)", "execution_count": 23, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}]}, {"metadata": {"id": "9MuabGo-4JTn"}, "id": "9MuabGo-4JTn", "cell_type": "markdown", "source": "On \u00e9valut le nombre de composante."}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "outputId": "5565e265-999d-4ac8-9b88-0b1132e78bd5", "id": "fO7MUiLy4JTn", "trusted": true}, "id": "fO7MUiLy4JTn", "cell_type": "code", "source": "# Calculate explained variance\nexplained_variance = np.cumsum(pca_model.explainedVariance.toArray())\n\n# Determine number of components to explain desired variance (e.g., 95%)\ndesired_variance = 0.999\nn_components = np.argmax(explained_variance >= desired_variance) + 1\n\n# afficher nb de components\nprint(n_components)", "execution_count": 24, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "1129", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "explained_variance.shape", "execution_count": 25, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "(1280,)", "name": "stdout"}]}, {"metadata": {"id": "Nh9-md0G4JTo"}, "id": "Nh9-md0G4JTo", "cell_type": "markdown", "source": "Puis on applique de nouveau la pca avec le bon nombre de composante."}, {"metadata": {"id": "sqEcIXc94JTo", "trusted": true}, "id": "sqEcIXc94JTo", "cell_type": "code", "source": "pca = PCA(k=n_components, inputCol=\"features_vector\", outputCol=\"pca_features\")\npca_model = pca.fit(features_vector_df)\npca_features_df = pca_model.transform(features_vector_df).select(\"path\", \"label\", \"pca_features\")", "execution_count": 26, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}]}, {"metadata": {"colab": {"referenced_widgets": [""]}, "id": "06a930b3", "outputId": "8eacb427-ef57-41ab-927f-3d2e51ebdf47", "trusted": true}, "id": "06a930b3", "cell_type": "code", "source": "print(PATH_Result)", "execution_count": 27, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "s3://p8-lucasdata/Results", "name": "stdout"}]}, {"metadata": {"colab": {"referenced_widgets": [""]}, "id": "7c53ddd5", "outputId": "56377a7d-dbf2-4238-c081-ad920c3baf96", "trusted": true}, "id": "7c53ddd5", "cell_type": "code", "source": "pca_features_df.write.mode(\"overwrite\").parquet(PATH_Result)", "execution_count": 28, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}]}, {"metadata": {"id": "1fe01b72"}, "id": "1fe01b72", "cell_type": "markdown", "source": "### 4.10.6 Chargement des donn\u00e9es enregistr\u00e9es et validation du r\u00e9sultat"}, {"metadata": {"colab": {"referenced_widgets": [""]}, "id": "db18a784", "outputId": "f00610c0-366a-4541-e49b-692ae97228b0", "trusted": true}, "id": "db18a784", "cell_type": "code", "source": "df = pd.read_parquet(PATH_Result, engine='pyarrow')", "execution_count": 29, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}]}, {"metadata": {"colab": {"referenced_widgets": [""]}, "id": "d750d2a8", "outputId": "a4ebc65b-5ec9-41de-db24-c8aed22fb546", "trusted": true}, "id": "d750d2a8", "cell_type": "code", "source": "df.head()", "execution_count": 30, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "                                                path  ...                                       pca_features\n0     s3://p8-lucasdata/Test/Watermelon/r_83_100.jpg  ...  {'type': 1, 'size': None, 'indices': None, 'va...\n1     s3://p8-lucasdata/Test/Watermelon/r_92_100.jpg  ...  {'type': 1, 'size': None, 'indices': None, 'va...\n2  s3://p8-lucasdata/Test/Pineapple Mini/259_100.jpg  ...  {'type': 1, 'size': None, 'indices': None, 'va...\n3      s3://p8-lucasdata/Test/Watermelon/284_100.jpg  ...  {'type': 1, 'size': None, 'indices': None, 'va...\n4  s3://p8-lucasdata/Test/Pineapple Mini/128_100.jpg  ...  {'type': 1, 'size': None, 'indices': None, 'va...\n\n[5 rows x 3 columns]", "name": "stdout"}]}, {"metadata": {"colab": {"referenced_widgets": [""]}, "id": "b29205ff", "outputId": "b44a9fc2-35bd-4004-e023-35622d6da09c", "trusted": true}, "id": "b29205ff", "cell_type": "code", "source": "df.loc[0,'pca_features']['values'].shape", "execution_count": 35, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "(1129,)", "name": "stdout"}]}, {"metadata": {"id": "72974aab"}, "id": "72974aab", "cell_type": "markdown", "source": "<u>On peut \u00e9galement constater la pr\u00e9sence des fichiers <br />\n    au format \"**parquet**\" sur le **serveur S3**</u> :\n\n![Affichage des r\u00e9sultats sur S3](img/S3_Results.png)\n\n## 4.11 Suivi de l'avancement des t\u00e2ches avec le Serveur d'Historique Spark\n\nIl est possible de voir l'avancement des t\u00e2ches en cours <br />\navec le **serveur d'historique Spark**.\n\n![Acc\u00e8s au serveur d'historique spark](img/EMR_serveur_historique_spark_acces.png)\n\n**Il est \u00e9galement possible de revenir et d'\u00e9tudier les t\u00e2ches <br />\nqui ont \u00e9t\u00e9 r\u00e9alis\u00e9, afin de debugger, optimiser les futurs <br />\nt\u00e2ches \u00e0 r\u00e9aliser.**\n\n<u>Lorsque la commande \"**features_df.write.mode(\"overwrite\").parquet(PATH_Result)**\" <br />\n\u00e9tait en cours, nous pouvions observer son \u00e9tat d'avancement</u> :\n\n![Progression execution script](img/EMR_jupyterhub_avancement.png)\n\n<u>Le **serveur d'historique Spark** nous permet une vision beaucoup plus pr\u00e9cise <br />\nde l'ex\u00e9cution des diff\u00e9rentes t\u00e2che sur les diff\u00e9rentes machines du cluster</u> :\n\n![Suivi des t\u00e2ches spark](img/EMR_SHSpark_01.png)\n\nOn peut \u00e9galement constater que notre cluster de calcul a mis <br />\nun tout petit peu **moins de 8 minutes** pour traiter les **22 688 images**.\n\n![Temps de traitement](img/EMR_SHSpark_02.png)\n"}, {"metadata": {"id": "b22d65bf"}, "id": "b22d65bf", "cell_type": "markdown", "source": "## 4.12 R\u00e9siliation de l'instance EMR\n\nNotre travail est maintenant termin\u00e9. <br />\nLe cluster de machines EMR est **factur\u00e9 \u00e0 la demande**, <br />\net nous continuons d'\u00eatre factur\u00e9 m\u00eame lorsque <br />\nles machines sont au repos.<br />\nPour **optimiser la facturation**, il nous faut <br />\nmaintenant **r\u00e9silier le cluster**.\n\n<u>Je r\u00e9alise cette commande depuis l'interface AWS</u> :\n\n1. Commencez par **d\u00e9sactiver le tunnel ssh dans FoxyProxy** pour \u00e9viter des probl\u00e8mes de **timeout**.\n![D\u00e9sactivation de FoxyProxy](img/EMR_foxyproxy_desactivation.png)\n2. Cliquez sur \"**R\u00e9silier**\"\n![Cliquez sur R\u00e9silier](img/EMR_resiliation_01.png)\n3. Confirmez la r\u00e9siliation\n![Confirmez la r\u00e9siliation](img/EMR_resiliation_02.png)\n4. La r\u00e9siliation prend environ **1 minute**\n![R\u00e9siliation en cours](img/EMR_resiliation_03.png)\n5. La r\u00e9siliation est effectu\u00e9e\n![R\u00e9siliation termin\u00e9e](img/EMR_resiliation_04.png)\n\n## 4.13 Cloner le serveur EMR (si besoin)\n\nSi nous devons de nouveau ex\u00e9cuter notre notebook dans les m\u00eames conditions, <br />\nil nous suffit de **cloner notre cluster** et ainsi en obtenir une copie fonctionnelle <br />\nsous 15/20 minutes, le temps de son instanciation.\n\n<u>Pour cela deux solutions</u> :\n1. <u>Depuis l'interface AWS</u> :\n 1. Cliquez sur \"**Cloner**\"\n   ![Cloner un cluster](img/EMR_cloner_01.png)\n 2. Dans notre cas nous ne souhaitons pas inclure d'\u00e9tapes\n   ![Ne pas inclure d'\u00e9tapes](img/EMR_cloner_02.png)\n 3. La configuration du cluster est recr\u00e9\u00e9e \u00e0 l\u2019identique. <br />\n    On peut revenir sur les diff\u00e9rentes \u00e9tapes si on souhaite apporter des modifications<br />\n    Quand tout est pr\u00eat, cliquez sur \"**Cr\u00e9er un cluster**\"\n  ![V\u00e9rification/Modification/Cr\u00e9er un cluster](img/EMR_cloner_03.png)\n2. <u>En ligne de commande</u> (avec AWS CLI d'install\u00e9 et de configur\u00e9 et en s'assurant <br />\n   de s'attribuer les droits n\u00e9cessaires sur le compte AMI utilis\u00e9)\n 1. Cliquez sur \"**Exporter AWS CLI**\"\n ![Exporter AWS CLI](img/EMR_cloner_cli_01.png)\n 2. Copier/Coller la commande **depuis un terminal**\n ![Copier Coller Commande](img/EMR_cloner_cli_02.png)\n\n## 4.14 Arborescence du serveur S3 \u00e0 la fin du projet\n\n<u>Pour information, voici **l'arborescence compl\u00e8te de mon bucket S3 p8-data** \u00e0 la fin du projet</u> : <br />\n*Par soucis de lisibilit\u00e9, je ne liste pas les 131 sous dossiers du r\u00e9pertoire \"Test\"*\n\n1. Results/_SUCCESS\n1. Results/part-00000-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n1. Results/part-00001-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n1. Results/part-00002-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n1. Results/part-00003-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n1. Results/part-00004-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n1. Results/part-00005-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n1. Results/part-00006-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n1. Results/part-00007-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n1. Results/part-00008-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n1. Results/part-00009-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n1. Results/part-00010-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n1. Results/part-00011-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n1. Results/part-00012-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n1. Results/part-00013-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n1. Results/part-00014-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n1. Results/part-00015-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n1. Results/part-00016-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n1. Results/part-00017-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n1. Results/part-00018-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n1. Results/part-00019-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n1. Results/part-00020-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n1. Results/part-00021-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n1. Results/part-00022-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n1. Results/part-00023-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n1. Test/\n1. bootstrap-emr.sh\n1. jupyter-s3-conf.json\n1. jupyter/jovyan/.s3keep\n1. jupyter/jovyan/P8_01_Notebook.ipynb\n1. jupyter/jovyan/_metadata\n1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.aws-editors-workspace-metadata/\n1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.aws-editors-workspace-metadata/file-perm.sqlite\n1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.aws-editors-workspace-metadata/nbconvert/\n1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.aws-editors-workspace-metadata/nbconvert/templates/\n1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.aws-editors-workspace-metadata/nbconvert/templates/html/\n1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.aws-editors-workspace-metadata/nbconvert/templates/latex/\n1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.aws-editors-workspace-metadata/nbsignatures.db\n1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.aws-editors-workspace-metadata/notebook_secret\n1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.ipynb_checkpoints/\n1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.ipynb_checkpoints/Untitled-checkpoint.ipynb\n1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.ipynb_checkpoints/Untitled1-checkpoint.ipynb\n1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.ipynb_checkpoints/test3-checkpoint.ipynb\n1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/Untitled.ipynb\n1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/Untitled1.ipynb\n1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/test3.ipynb"}, {"metadata": {"id": "4eba46f9"}, "id": "4eba46f9", "cell_type": "markdown", "source": "# 5. Conclusion\n\nNous avons r\u00e9alis\u00e9 ce projet **en deux temps** en tenant <br />\ncompte des contraintes qui nous ont \u00e9t\u00e9 impos\u00e9es.\n\nNous avons **dans un premier temps d\u00e9velopp\u00e9 notre solution en local** <br />\nsur une machine virtuelle dans un environnement Linux Ubuntu.\n\nLa <u>premi\u00e8re phase</u> a consist\u00e9 \u00e0 **installer l'environnement de travail Spark**. <br />\n**Spark** a un param\u00e8tre qui nous permet de travaill\u00e9 en local et nous permet <br />\nainsi de **simuler du calcul partag\u00e9** en consid\u00e9rant <br />\n**chaque c\u0153ur d'un processeur comme un worker ind\u00e9pendant**.<br />\nNous avons travaill\u00e9 sur un plus **petit jeu de donn\u00e9e**, l'id\u00e9e \u00e9tait <br />\nsimplement de **valider le bon fonctionnement de la solution**.\n\nNous avons fait le choix de r\u00e9aliser du **transfert learning** <br />\n\u00e0 partir du model **MobileNetV2**.<br />\nCe mod\u00e8le a \u00e9t\u00e9 retenu pour sa **l\u00e9g\u00e8ret\u00e9** et sa **rapidit\u00e9 d'ex\u00e9cution** <br />\nainsi que pour la **faible dimension de son vecteur en sortie**.\n\nLes r\u00e9sultats ont \u00e9t\u00e9 enregistr\u00e9s sur disque en plusieurs <br />\npartitions au format \"**parquet**\".\n\n<u>**La solution a parfaitement fonctionn\u00e9 en mode local**</u>.\n\nLa <u>deuxi\u00e8me phase</u> a consist\u00e9 \u00e0 cr\u00e9er un **r\u00e9el cluster de calculs**. <br />\nL'objectif \u00e9tait de pouvoir **anticiper une future augmentation de la charge de travail**.\n\nLe meilleur choix retenu a \u00e9t\u00e9 l'utilisation du prestataire de services **Amazon Web Services** <br />\nqui nous permet de **louer \u00e0 la demande de la puissance de calculs**, <br />\npour un **co\u00fbt tout \u00e0 fait acceptable**.<br />\nCe service se nomme **EC2** et se classe parmi les offres **Infrastructure As A Service** (IAAS).\n\nNous sommes allez plus loin en utilisant un service de plus <br />\nhaut niveau (**Plateforme As A Service** PAAS)<br />\nen utilisant le service **EMR** qui nous permet d'un seul coup <br />\nd'**instancier plusieurs serveur (un cluster)** sur lesquels <br />\nnous avons pu demander l'installation et la configuration de plusieurs<br />\nprogrammes et librairies n\u00e9cessaires \u00e0 notre projet comme **Spark**, <br />\n**Hadoop**, **JupyterHub** ainsi que la librairie **TensorFlow**.\n\nEn plus d'\u00eatre plus **rapide et efficace \u00e0 mettre en place**, nous avons <br />\nla **certitude du bon fonctionnement de la solution**, celle-ci ayant \u00e9t\u00e9 <br />\npr\u00e9alablement valid\u00e9 par les ing\u00e9nieurs d'Amazon.\n\nNous avons \u00e9galement pu installer, sans difficult\u00e9, **les packages <br />\nn\u00e9cessaires sur l'ensembles des machines du cluster**.\n\nEnfin, avec tr\u00e8s peu de modification, et plus simplement encore, <br />\nnous avons pu **ex\u00e9cuter notre notebook comme nous l'avions fait localement**.<br />\nNous avons cette fois-ci ex\u00e9cut\u00e9 le traitement sur **l'ensemble des images de notre dossier \"Test\"**.\n\nNous avons opt\u00e9 pour le service **Amazon S3** pour **stocker les donn\u00e9es de notre projet**. <br />\nS3 offre, pour un faible co\u00fbt, toutes les conditions dont nous avons besoin pour stocker <br />\net exploiter de mani\u00e8re efficace nos donn\u00e9es.<br />\nL'espace allou\u00e9 est potentiellement **illimit\u00e9**, mais les co\u00fbts seront fonction de l'espace utilis\u00e9.\n\nIl nous sera **facile de faire face \u00e0 une mont\u00e9 de la charge de travail** en **redimensionnant** <br />\nsimplement notre cluster de machines (horizontalement et/ou verticalement au besoin), <br />\nles co\u00fbts augmenteront en cons\u00e9quence mais resteront nettement inf\u00e9rieurs aux co\u00fbts engendr\u00e9s <br />\npar l'achat de mat\u00e9riels ou par la location de serveurs d\u00e9di\u00e9s."}], "metadata": {"kernelspec": {"name": "pysparkkernel", "display_name": "PySpark", "language": "python"}, "language_info": {"name": "pyspark", "mimetype": "text/x-python", "codemirror_mode": {"name": "python", "version": 3}, "file_extension": ".py", "pygments_lexer": "python3"}, "toc": {"base_numbering": 1, "nav_menu": {}, "number_sections": true, "sideBar": true, "skip_h1_title": false, "title_cell": "Table of Contents", "title_sidebar": "Contents", "toc_cell": false, "toc_position": {"height": "calc(100% - 180px)", "left": "10px", "top": "150px", "width": "432.4px"}, "toc_section_display": true, "toc_window_display": true}, "colab": {"provenance": [], "toc_visible": true}}, "nbformat": 4, "nbformat_minor": 5}